[2025-03-10T16:14:24.599+0600] {processor.py:186} INFO - Started process (PID=42433) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:14:24.601+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T16:14:24.606+0600] {logging_mixin.py:190} INFO - [2025-03-10T16:14:24.606+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:14:24.623+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:14:24.678+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.145 seconds
[2025-03-10T16:16:38.460+0600] {processor.py:186} INFO - Started process (PID=43000) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:16:38.481+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T16:16:38.483+0600] {logging_mixin.py:190} INFO - [2025-03-10T16:16:38.482+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:16:38.489+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:16:38.513+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.067 seconds
[2025-03-10T16:18:29.661+0600] {processor.py:186} INFO - Started process (PID=43568) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:18:29.666+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T16:18:29.670+0600] {logging_mixin.py:190} INFO - [2025-03-10T16:18:29.667+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:18:29.676+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:18:29.720+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.082 seconds
[2025-03-10T16:20:29.754+0600] {processor.py:186} INFO - Started process (PID=43851) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:20:29.758+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T16:20:29.763+0600] {logging_mixin.py:190} INFO - [2025-03-10T16:20:29.760+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:20:29.773+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:20:29.810+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.086 seconds
[2025-03-10T16:22:29.465+0600] {processor.py:186} INFO - Started process (PID=44242) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:22:29.471+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T16:22:29.474+0600] {logging_mixin.py:190} INFO - [2025-03-10T16:22:29.473+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:22:29.479+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:22:29.502+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.048 seconds
[2025-03-10T16:24:24.747+0600] {processor.py:186} INFO - Started process (PID=44572) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:24:24.754+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T16:24:24.761+0600] {logging_mixin.py:190} INFO - [2025-03-10T16:24:24.760+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:24:24.771+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:24:24.815+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.094 seconds
[2025-03-10T16:26:30.505+0600] {processor.py:186} INFO - Started process (PID=44711) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:26:30.511+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T16:26:30.517+0600] {logging_mixin.py:190} INFO - [2025-03-10T16:26:30.513+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:26:30.531+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:26:30.647+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.178 seconds
[2025-03-10T16:28:35.787+0600] {processor.py:186} INFO - Started process (PID=44874) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:28:35.795+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T16:28:35.798+0600] {logging_mixin.py:190} INFO - [2025-03-10T16:28:35.797+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:28:35.806+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T16:28:35.837+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.080 seconds
[2025-03-10T17:14:47.082+0600] {processor.py:186} INFO - Started process (PID=9305) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:14:47.087+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:14:47.102+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:14:47.099+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:14:47.199+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:14:47.472+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:14:47.471+0600] {override.py:1930} INFO - Created Permission View: can edit on DAG:E2E_kafka_producer_data_ETL_dag
[2025-03-10T17:14:47.486+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:14:47.486+0600] {override.py:1930} INFO - Created Permission View: can read on DAG:E2E_kafka_producer_data_ETL_dag
[2025-03-10T17:14:47.497+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:14:47.496+0600] {override.py:1930} INFO - Created Permission View: can delete on DAG:E2E_kafka_producer_data_ETL_dag
[2025-03-10T17:14:47.511+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:14:47.511+0600] {override.py:1930} INFO - Created Permission View: can create on DAG Run:E2E_kafka_producer_data_ETL_dag
[2025-03-10T17:14:47.520+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:14:47.519+0600] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:E2E_kafka_producer_data_ETL_dag
[2025-03-10T17:14:47.529+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:14:47.529+0600] {override.py:1930} INFO - Created Permission View: can read on DAG Run:E2E_kafka_producer_data_ETL_dag
[2025-03-10T17:14:47.537+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:14:47.537+0600] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:E2E_kafka_producer_data_ETL_dag
[2025-03-10T17:14:47.538+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:14:47.538+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:14:47.556+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:14:47.555+0600] {dag.py:3262} INFO - Creating ORM DAG for E2E_kafka_producer_data_ETL_dag
[2025-03-10T17:14:47.557+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:14:47.556+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:14:47.577+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.536 seconds
[2025-03-10T17:16:10.507+0600] {processor.py:186} INFO - Started process (PID=9635) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:16:10.515+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:16:10.518+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:16:10.518+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:16:10.550+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:16:10.567+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:16:10.567+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:16:10.584+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:16:10.584+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:16:10.640+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.141 seconds
[2025-03-10T17:17:03.796+0600] {processor.py:186} INFO - Started process (PID=9886) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:17:03.801+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:17:03.808+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:17:03.807+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:17:03.866+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:17:03.885+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:17:03.885+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:17:03.904+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:17:03.903+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:17:03.935+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.155 seconds
[2025-03-10T17:17:55.527+0600] {processor.py:186} INFO - Started process (PID=10142) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:17:55.534+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:17:55.540+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:17:55.539+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:17:55.574+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:17:55.590+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:17:55.590+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:17:55.606+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:17:55.606+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:17:55.633+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.118 seconds
[2025-03-10T17:18:39.526+0600] {processor.py:186} INFO - Started process (PID=10458) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:18:39.528+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:18:39.531+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:18:39.530+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:18:39.595+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:18:39.629+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:18:39.629+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:18:39.668+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:18:39.668+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:18:39.752+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.235 seconds
[2025-03-10T17:19:44.856+0600] {processor.py:186} INFO - Started process (PID=10694) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:19:44.864+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:19:44.871+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:19:44.870+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:19:44.962+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:19:45.027+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:19:45.026+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:19:45.063+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:19:45.062+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:19:45.126+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.284 seconds
[2025-03-10T17:20:39.038+0600] {processor.py:186} INFO - Started process (PID=10920) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:20:39.045+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:20:39.048+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:20:39.047+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:20:39.080+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:20:39.098+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:20:39.098+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:20:39.125+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:20:39.125+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:20:39.166+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.140 seconds
[2025-03-10T17:21:30.387+0600] {processor.py:186} INFO - Started process (PID=11141) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:21:30.393+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:21:30.396+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:21:30.395+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:21:30.428+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:21:30.448+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:21:30.447+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:21:30.466+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:21:30.466+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:21:30.495+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.122 seconds
[2025-03-10T17:22:18.156+0600] {processor.py:186} INFO - Started process (PID=11360) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:22:18.170+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:22:18.174+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:22:18.173+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:22:18.206+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:22:18.225+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:22:18.225+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:22:18.242+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:22:18.242+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:22:18.269+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.122 seconds
[2025-03-10T17:23:06.665+0600] {processor.py:186} INFO - Started process (PID=11627) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:23:06.672+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:23:06.675+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:23:06.674+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:23:06.713+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:23:06.739+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:23:06.739+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:23:06.760+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:23:06.760+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:23:06.797+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.141 seconds
[2025-03-10T17:24:01.418+0600] {processor.py:186} INFO - Started process (PID=11871) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:24:01.425+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:24:01.432+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:24:01.431+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:24:01.489+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:24:01.524+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:24:01.524+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:24:01.542+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:24:01.542+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:24:01.575+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.180 seconds
[2025-03-10T17:24:57.394+0600] {processor.py:186} INFO - Started process (PID=12102) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:24:57.398+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:24:57.403+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:24:57.401+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:24:57.434+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:24:57.452+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:24:57.451+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:24:57.469+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:24:57.468+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:24:57.496+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.117 seconds
[2025-03-10T17:25:51.138+0600] {processor.py:186} INFO - Started process (PID=12338) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:25:51.139+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:25:51.142+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:25:51.141+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:25:51.175+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:25:51.194+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:25:51.193+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:25:51.213+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:25:51.213+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:25:51.238+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.111 seconds
[2025-03-10T17:26:43.551+0600] {processor.py:186} INFO - Started process (PID=12565) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:26:43.558+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:26:43.564+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:26:43.563+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:26:43.604+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:26:43.621+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:26:43.621+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:26:43.637+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:26:43.637+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:26:43.663+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.136 seconds
[2025-03-10T17:27:34.213+0600] {processor.py:186} INFO - Started process (PID=12920) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:27:34.214+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:27:34.218+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:27:34.217+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:27:34.271+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:27:34.302+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:27:34.302+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:27:34.326+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:27:34.326+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:27:34.367+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.166 seconds
[2025-03-10T17:28:35.583+0600] {processor.py:186} INFO - Started process (PID=13222) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:28:35.591+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:28:35.598+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:28:35.596+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:28:35.644+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:28:35.667+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:28:35.667+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:28:35.683+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:28:35.683+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:28:35.725+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.166 seconds
[2025-03-10T17:29:26.048+0600] {processor.py:186} INFO - Started process (PID=13489) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:29:26.051+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:29:26.054+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:29:26.053+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:29:26.092+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:29:26.113+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:29:26.112+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:29:26.137+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:29:26.137+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:29:26.172+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.132 seconds
[2025-03-10T17:30:16.880+0600] {processor.py:186} INFO - Started process (PID=13760) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:30:16.887+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:30:16.891+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:30:16.891+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:30:16.936+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:30:16.961+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:30:16.960+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:30:16.987+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:30:16.986+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:30:17.020+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.152 seconds
[2025-03-10T17:31:09.205+0600] {processor.py:186} INFO - Started process (PID=14011) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:31:09.211+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:31:09.214+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:31:09.213+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:31:09.247+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:31:09.265+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:31:09.265+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:31:09.283+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:31:09.283+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:31:09.312+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.116 seconds
[2025-03-10T17:31:59.874+0600] {processor.py:186} INFO - Started process (PID=14270) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:31:59.881+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:31:59.884+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:31:59.883+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:31:59.913+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:31:59.932+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:31:59.932+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:31:59.949+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:31:59.948+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:31:59.974+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.113 seconds
[2025-03-10T17:32:50.064+0600] {processor.py:186} INFO - Started process (PID=14555) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:32:50.070+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:32:50.074+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:32:50.073+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:32:50.111+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:32:50.128+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:32:50.128+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:32:50.145+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:32:50.144+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:32:50.174+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.129 seconds
[2025-03-10T17:33:38.612+0600] {processor.py:186} INFO - Started process (PID=14810) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:33:38.619+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:33:38.621+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:33:38.621+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:33:38.657+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:33:38.675+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:33:38.675+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:33:38.694+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:33:38.693+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:33:38.721+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.115 seconds
[2025-03-10T17:34:33.473+0600] {processor.py:186} INFO - Started process (PID=15044) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:34:33.479+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:34:33.482+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:34:33.482+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:34:33.516+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:34:33.534+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:34:33.534+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:34:33.553+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:34:33.552+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:34:33.582+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.118 seconds
[2025-03-10T17:35:28.678+0600] {processor.py:186} INFO - Started process (PID=15275) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:35:28.687+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:35:28.694+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:35:28.692+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:35:28.759+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:35:28.787+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:35:28.787+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:35:28.803+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:35:28.802+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:35:28.835+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.184 seconds
[2025-03-10T17:36:13.929+0600] {processor.py:186} INFO - Started process (PID=15503) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:36:13.939+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:36:13.948+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:36:13.946+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:36:13.997+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:36:14.017+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:36:14.016+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:36:14.035+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:36:14.034+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:36:14.065+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.163 seconds
[2025-03-10T17:37:05.509+0600] {processor.py:186} INFO - Started process (PID=15762) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:37:05.512+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:37:05.515+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:37:05.515+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:37:05.550+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:37:05.571+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:37:05.570+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:37:05.589+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:37:05.589+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:37:05.623+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.124 seconds
[2025-03-10T17:37:57.122+0600] {processor.py:186} INFO - Started process (PID=16054) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:37:57.129+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:37:57.131+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:37:57.131+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:37:57.163+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:37:57.182+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:37:57.182+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:37:57.202+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:37:57.202+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:37:57.237+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.124 seconds
[2025-03-10T17:38:46.398+0600] {processor.py:186} INFO - Started process (PID=16308) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:38:46.406+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:38:46.409+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:38:46.409+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:38:46.441+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:38:46.458+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:38:46.458+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:38:46.476+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:38:46.476+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:38:46.503+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.118 seconds
[2025-03-10T17:39:39.066+0600] {processor.py:186} INFO - Started process (PID=16554) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:39:39.073+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:39:39.076+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:39:39.075+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:39:39.115+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:39:39.137+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:39:39.137+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:39:39.157+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:39:39.156+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:39:39.185+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.129 seconds
[2025-03-10T17:40:32.520+0600] {processor.py:186} INFO - Started process (PID=16782) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:40:32.526+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:40:32.530+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:40:32.529+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:40:32.566+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:40:32.585+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:40:32.585+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:40:32.602+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:40:32.602+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:40:32.629+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.122 seconds
[2025-03-10T17:41:25.099+0600] {processor.py:186} INFO - Started process (PID=17041) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:41:25.101+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:41:25.103+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:41:25.103+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:41:25.136+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:41:25.154+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:41:25.153+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:41:25.171+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:41:25.171+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:41:25.197+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.105 seconds
[2025-03-10T17:42:20.110+0600] {processor.py:186} INFO - Started process (PID=17270) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:42:20.116+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:42:20.120+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:42:20.119+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:42:20.157+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:42:20.176+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:42:20.175+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:42:20.196+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:42:20.196+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:42:20.239+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.137 seconds
[2025-03-10T17:43:12.908+0600] {processor.py:186} INFO - Started process (PID=17559) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:43:12.914+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:43:12.917+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:43:12.917+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:43:12.957+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:43:12.981+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:43:12.981+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:43:13.007+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:43:13.007+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:43:13.052+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.155 seconds
[2025-03-10T17:44:01.614+0600] {processor.py:186} INFO - Started process (PID=17823) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:44:01.621+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:44:01.627+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:44:01.626+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:44:01.688+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:44:01.708+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:44:01.708+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:44:01.726+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:44:01.726+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:44:01.754+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.156 seconds
[2025-03-10T17:44:55.271+0600] {processor.py:186} INFO - Started process (PID=18086) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:44:55.277+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:44:55.280+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:44:55.279+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:44:55.313+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:44:55.333+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:44:55.333+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:44:55.351+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:44:55.351+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:44:55.380+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.119 seconds
[2025-03-10T17:45:47.424+0600] {processor.py:186} INFO - Started process (PID=18359) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:45:47.434+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:45:47.443+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:45:47.443+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:45:47.548+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:45:47.572+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:45:47.572+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:45:47.593+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:45:47.593+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:45:47.624+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.211 seconds
[2025-03-10T17:46:40.872+0600] {processor.py:186} INFO - Started process (PID=18621) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:46:40.874+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:46:40.880+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:46:40.879+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:46:40.939+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:46:40.971+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:46:40.971+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:46:41.005+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:46:41.005+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:46:41.054+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.196 seconds
[2025-03-10T17:47:37.480+0600] {processor.py:186} INFO - Started process (PID=18885) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:47:37.488+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:47:37.494+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:47:37.493+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:47:37.536+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:47:37.682+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:47:37.682+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:47:37.698+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:47:37.697+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:47:37.728+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.268 seconds
[2025-03-10T17:48:31.156+0600] {processor.py:186} INFO - Started process (PID=19149) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:48:31.162+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:48:31.164+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:48:31.164+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:48:31.195+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:48:31.212+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:48:31.212+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:48:31.227+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:48:31.227+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:48:31.258+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.110 seconds
[2025-03-10T17:49:22.011+0600] {processor.py:186} INFO - Started process (PID=19763) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:49:22.012+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:49:22.015+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:49:22.014+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:49:22.049+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:49:22.071+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:49:22.070+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:49:22.094+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:49:22.093+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:49:22.123+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.121 seconds
[2025-03-10T17:50:14.593+0600] {processor.py:186} INFO - Started process (PID=20415) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:50:14.602+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:50:14.606+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:50:14.605+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:50:14.641+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:50:14.659+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:50:14.658+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:50:14.675+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:50:14.675+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:50:14.714+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.138 seconds
[2025-03-10T17:51:03.279+0600] {processor.py:186} INFO - Started process (PID=20650) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:51:03.286+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:51:03.291+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:51:03.290+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:51:03.349+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:51:03.376+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:51:03.375+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:51:03.394+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:51:03.394+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:51:03.428+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.166 seconds
[2025-03-10T17:51:52.030+0600] {processor.py:186} INFO - Started process (PID=20896) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:51:52.038+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:51:52.042+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:51:52.041+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:51:52.093+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:51:52.110+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:51:52.110+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:51:52.126+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:51:52.126+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:51:52.154+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.140 seconds
[2025-03-10T17:52:39.494+0600] {processor.py:186} INFO - Started process (PID=21141) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:52:39.501+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:52:39.506+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:52:39.505+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:52:39.547+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:52:39.567+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:52:39.566+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:52:39.583+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:52:39.583+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:52:39.607+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.120 seconds
[2025-03-10T17:53:30.356+0600] {processor.py:186} INFO - Started process (PID=21415) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:53:30.367+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:53:30.387+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:53:30.384+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:53:30.488+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:53:30.521+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:53:30.521+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:53:30.547+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:53:30.547+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:53:30.581+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.247 seconds
[2025-03-10T17:54:22.396+0600] {processor.py:186} INFO - Started process (PID=21657) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:54:22.403+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:54:22.406+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:54:22.405+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:54:22.440+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:54:22.459+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:54:22.459+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:54:22.477+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:54:22.477+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:54:22.504+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.116 seconds
[2025-03-10T17:55:13.497+0600] {processor.py:186} INFO - Started process (PID=21894) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:55:13.503+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:55:13.506+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:55:13.506+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:55:13.536+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:55:13.556+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:55:13.555+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:55:13.571+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:55:13.570+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:55:13.594+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.104 seconds
[2025-03-10T17:56:01.025+0600] {processor.py:186} INFO - Started process (PID=22126) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:56:01.029+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:56:01.031+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:56:01.031+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:56:01.067+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:56:01.089+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:56:01.089+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:56:01.108+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:56:01.108+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:56:01.137+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.120 seconds
[2025-03-10T17:56:50.465+0600] {processor.py:186} INFO - Started process (PID=22367) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:56:50.473+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:56:50.477+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:56:50.476+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:56:50.523+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:56:50.553+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:56:50.552+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:56:50.580+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:56:50.580+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:56:50.611+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.155 seconds
[2025-03-10T17:57:40.923+0600] {processor.py:186} INFO - Started process (PID=22632) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:57:40.926+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:57:40.930+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:57:40.929+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:57:40.969+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:57:40.993+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:57:40.993+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:57:41.019+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:57:41.018+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:57:41.047+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.134 seconds
[2025-03-10T17:58:28.883+0600] {processor.py:186} INFO - Started process (PID=22942) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:58:28.890+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:58:28.893+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:58:28.892+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:58:28.927+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:58:28.945+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:58:28.945+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:58:28.961+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:58:28.961+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:58:28.991+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.121 seconds
[2025-03-10T17:59:17.801+0600] {processor.py:186} INFO - Started process (PID=23168) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:59:17.804+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T17:59:17.806+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:59:17.806+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:59:17.840+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T17:59:17.858+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:59:17.857+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T17:59:17.880+0600] {logging_mixin.py:190} INFO - [2025-03-10T17:59:17.879+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T17:59:17.905+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.111 seconds
[2025-03-10T18:00:02.182+0600] {processor.py:186} INFO - Started process (PID=23386) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:00:02.188+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:00:02.192+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:00:02.191+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:00:02.238+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:00:02.257+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:00:02.257+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:00:02.278+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:00:02.278+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:00:02.309+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.138 seconds
[2025-03-10T18:00:44.593+0600] {processor.py:186} INFO - Started process (PID=23678) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:00:44.599+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:00:44.602+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:00:44.602+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:00:44.639+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:00:44.658+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:00:44.658+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:00:44.682+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:00:44.681+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:00:44.713+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.128 seconds
[2025-03-10T18:01:29.592+0600] {processor.py:186} INFO - Started process (PID=23896) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:01:29.598+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:01:29.603+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:01:29.602+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:01:29.648+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:01:29.674+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:01:29.673+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:01:29.691+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:01:29.690+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:01:29.718+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.146 seconds
[2025-03-10T18:02:16.004+0600] {processor.py:186} INFO - Started process (PID=24117) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:02:16.007+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:02:16.010+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:02:16.010+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:02:16.043+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:02:16.062+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:02:16.062+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:02:16.078+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:02:16.077+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:02:16.101+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.109 seconds
[2025-03-10T18:03:00.303+0600] {processor.py:186} INFO - Started process (PID=24370) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:03:00.304+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:03:00.307+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:03:00.307+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:03:00.343+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:03:00.366+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:03:00.366+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:03:00.385+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:03:00.385+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:03:00.419+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.126 seconds
[2025-03-10T18:03:46.311+0600] {processor.py:186} INFO - Started process (PID=24589) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:03:46.316+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:03:46.319+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:03:46.318+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:03:46.350+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:03:46.369+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:03:46.369+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:03:46.386+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:03:46.385+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:03:46.417+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.115 seconds
[2025-03-10T18:04:34.256+0600] {processor.py:186} INFO - Started process (PID=24830) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:04:34.261+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:04:34.268+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:04:34.267+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:04:34.306+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:04:34.325+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:04:34.324+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:04:34.343+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:04:34.342+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:04:34.373+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.138 seconds
[2025-03-10T18:05:20.494+0600] {processor.py:186} INFO - Started process (PID=25055) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:05:20.497+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:05:20.501+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:05:20.501+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:05:20.535+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:05:20.554+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:05:20.554+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:05:20.573+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:05:20.573+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:05:20.600+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.117 seconds
[2025-03-10T18:06:08.638+0600] {processor.py:186} INFO - Started process (PID=25272) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:06:08.645+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:06:08.650+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:06:08.649+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:06:08.700+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:06:08.727+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:06:08.726+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:06:08.752+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:06:08.752+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:06:08.792+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.167 seconds
[2025-03-10T18:06:58.354+0600] {processor.py:186} INFO - Started process (PID=25495) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:06:58.360+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:06:58.365+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:06:58.364+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:06:58.400+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:06:58.421+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:06:58.421+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:06:58.440+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:06:58.439+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:06:58.468+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.124 seconds
[2025-03-10T18:07:47.005+0600] {processor.py:186} INFO - Started process (PID=25747) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:07:47.010+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:07:47.014+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:07:47.013+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:07:47.048+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:07:47.068+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:07:47.067+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:07:47.084+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:07:47.084+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:07:47.123+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.130 seconds
[2025-03-10T18:08:35.964+0600] {processor.py:186} INFO - Started process (PID=25970) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:08:35.965+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:08:35.968+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:08:35.968+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:08:36.002+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:08:36.020+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:08:36.020+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:08:36.038+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:08:36.038+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:08:36.066+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.111 seconds
[2025-03-10T18:09:24.242+0600] {processor.py:186} INFO - Started process (PID=26345) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:09:24.246+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:09:24.252+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:09:24.251+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:09:24.313+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:09:24.345+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:09:24.345+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:09:24.371+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:09:24.371+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:09:24.411+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.181 seconds
[2025-03-10T18:10:13.582+0600] {processor.py:186} INFO - Started process (PID=26607) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:10:13.586+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:10:13.589+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:10:13.589+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:10:13.621+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:10:13.639+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:10:13.639+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:10:13.659+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:10:13.658+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:10:13.693+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.119 seconds
[2025-03-10T18:11:01.612+0600] {processor.py:186} INFO - Started process (PID=26896) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:11:01.618+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:11:01.621+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:11:01.620+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:11:01.652+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:11:01.671+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:11:01.670+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:11:01.687+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:11:01.687+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:11:01.710+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.108 seconds
[2025-03-10T18:11:46.237+0600] {processor.py:186} INFO - Started process (PID=27172) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:11:46.244+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:11:46.247+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:11:46.246+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:11:46.280+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:11:46.301+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:11:46.300+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:11:46.317+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:11:46.317+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:11:46.340+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.110 seconds
[2025-03-10T18:12:30.861+0600] {processor.py:186} INFO - Started process (PID=27435) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:12:30.869+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:12:30.877+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:12:30.876+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:12:30.919+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:12:30.938+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:12:30.937+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:12:30.955+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:12:30.954+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:12:30.978+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.124 seconds
[2025-03-10T18:13:17.260+0600] {processor.py:186} INFO - Started process (PID=27754) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:13:17.266+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:13:17.269+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:13:17.269+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:13:17.301+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:13:17.319+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:13:17.319+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:13:17.335+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:13:17.335+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:13:17.371+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.119 seconds
[2025-03-10T18:14:02.247+0600] {processor.py:186} INFO - Started process (PID=28028) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:14:02.254+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:14:02.258+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:14:02.257+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:14:02.297+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:14:02.315+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:14:02.315+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:14:02.332+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:14:02.331+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:14:02.367+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.127 seconds
[2025-03-10T18:14:48.842+0600] {processor.py:186} INFO - Started process (PID=28312) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:14:48.848+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:14:48.851+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:14:48.851+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:14:48.883+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:14:48.901+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:14:48.901+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:14:48.920+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:14:48.919+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:14:48.944+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.110 seconds
[2025-03-10T18:15:33.565+0600] {processor.py:186} INFO - Started process (PID=28583) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:15:33.572+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:15:33.575+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:15:33.574+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:15:33.606+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:15:33.624+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:15:33.624+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:15:33.641+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:15:33.640+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:15:33.669+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.113 seconds
[2025-03-10T18:16:16.433+0600] {processor.py:186} INFO - Started process (PID=28848) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:16:16.439+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:16:16.443+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:16:16.442+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:16:16.484+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:16:16.501+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:16:16.501+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:16:16.518+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:16:16.518+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:16:16.550+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.128 seconds
[2025-03-10T18:17:04.827+0600] {processor.py:186} INFO - Started process (PID=29099) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:17:04.834+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:17:04.837+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:17:04.837+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:17:04.868+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:17:04.887+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:17:04.887+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:17:04.903+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:17:04.903+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:17:04.928+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.109 seconds
[2025-03-10T18:17:54.345+0600] {processor.py:186} INFO - Started process (PID=29376) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:17:54.351+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:17:54.354+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:17:54.354+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:17:54.385+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:17:54.404+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:17:54.404+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:17:54.420+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:17:54.420+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:17:54.448+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.112 seconds
[2025-03-10T18:18:37.638+0600] {processor.py:186} INFO - Started process (PID=29610) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:18:37.644+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:18:37.647+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:18:37.646+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:18:37.679+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:18:37.698+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:18:37.698+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:18:37.715+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:18:37.715+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:18:37.738+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.108 seconds
[2025-03-10T18:19:22.814+0600] {processor.py:186} INFO - Started process (PID=29842) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:19:22.818+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:19:22.821+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:19:22.821+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:19:22.852+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:19:22.870+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:19:22.870+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:19:22.886+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:19:22.885+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:19:22.921+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.115 seconds
[2025-03-10T18:20:07.886+0600] {processor.py:186} INFO - Started process (PID=30087) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:20:07.892+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:20:07.895+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:20:07.894+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:20:07.926+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:20:07.943+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:20:07.943+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:20:07.960+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:20:07.960+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:20:07.985+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.108 seconds
[2025-03-10T18:20:54.823+0600] {processor.py:186} INFO - Started process (PID=30341) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:20:54.830+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:20:54.833+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:20:54.832+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:20:54.864+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:20:54.881+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:20:54.881+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:20:54.898+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:20:54.898+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:20:54.923+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.107 seconds
[2025-03-10T18:21:41.278+0600] {processor.py:186} INFO - Started process (PID=30586) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:21:41.285+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:21:41.288+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:21:41.287+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:21:41.319+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:21:41.337+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:21:41.336+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:21:41.353+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:21:41.353+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:21:41.390+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.119 seconds
[2025-03-10T18:22:28.639+0600] {processor.py:186} INFO - Started process (PID=30807) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:22:28.640+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:22:28.643+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:22:28.643+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:22:28.674+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:22:28.692+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:22:28.692+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:22:28.708+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:22:28.708+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:22:28.749+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.119 seconds
[2025-03-10T18:23:16.976+0600] {processor.py:186} INFO - Started process (PID=31087) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:23:16.984+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:23:16.992+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:23:16.990+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:23:17.032+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:23:17.050+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:23:17.049+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:23:17.066+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:23:17.066+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:23:17.090+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.121 seconds
[2025-03-10T18:24:03.851+0600] {processor.py:186} INFO - Started process (PID=31334) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:24:03.857+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:24:03.860+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:24:03.859+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:24:03.891+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:24:03.910+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:24:03.909+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:24:03.926+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:24:03.925+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:24:03.949+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.106 seconds
[2025-03-10T18:24:49.112+0600] {processor.py:186} INFO - Started process (PID=31566) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:24:49.118+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:24:49.122+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:24:49.121+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:24:49.153+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:24:49.172+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:24:49.172+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:24:49.189+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:24:49.189+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:24:49.217+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.113 seconds
[2025-03-10T18:25:37.189+0600] {processor.py:186} INFO - Started process (PID=31820) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:25:37.196+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:25:37.199+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:25:37.198+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:25:37.230+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:25:37.249+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:25:37.249+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:25:37.265+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:25:37.264+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:25:37.289+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.108 seconds
[2025-03-10T18:26:23.435+0600] {processor.py:186} INFO - Started process (PID=32042) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:26:23.442+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:26:23.445+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:26:23.444+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:26:23.477+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:26:23.494+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:26:23.494+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:26:23.511+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:26:23.510+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:26:23.544+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.116 seconds
[2025-03-10T18:27:11.176+0600] {processor.py:186} INFO - Started process (PID=32288) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:27:11.183+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:27:11.185+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:27:11.185+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:27:11.217+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:27:11.235+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:27:11.235+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:27:11.252+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:27:11.252+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:27:11.288+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.120 seconds
[2025-03-10T18:27:57.424+0600] {processor.py:186} INFO - Started process (PID=32568) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:27:57.426+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:27:57.429+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:27:57.428+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:27:57.461+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:27:57.480+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:27:57.480+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:27:57.498+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:27:57.498+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:27:57.525+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.110 seconds
[2025-03-10T18:28:43.333+0600] {processor.py:186} INFO - Started process (PID=32801) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:28:43.339+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:28:43.342+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:28:43.342+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:28:43.374+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:28:43.393+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:28:43.393+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:28:43.410+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:28:43.410+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:28:43.605+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.280 seconds
[2025-03-10T18:29:30.644+0600] {processor.py:186} INFO - Started process (PID=33023) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:29:30.651+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:29:30.654+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:29:30.653+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:29:30.685+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:29:30.703+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:29:30.702+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:29:30.718+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:29:30.718+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:29:30.743+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.106 seconds
[2025-03-10T18:30:16.497+0600] {processor.py:186} INFO - Started process (PID=33270) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:30:16.504+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:30:16.507+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:30:16.507+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:30:16.538+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:30:16.556+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:30:16.556+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:30:16.574+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:30:16.573+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:30:16.772+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.282 seconds
[2025-03-10T18:31:06.897+0600] {processor.py:186} INFO - Started process (PID=33519) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:31:06.911+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:31:06.914+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:31:06.913+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:31:06.945+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:31:06.962+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:31:06.962+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:31:06.979+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:31:06.979+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:31:07.004+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.115 seconds
[2025-03-10T18:31:56.365+0600] {processor.py:186} INFO - Started process (PID=33753) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:31:56.371+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:31:56.374+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:31:56.374+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:31:56.405+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:31:56.424+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:31:56.424+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:31:56.440+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:31:56.440+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:31:56.476+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.119 seconds
[2025-03-10T18:32:46.304+0600] {processor.py:186} INFO - Started process (PID=34043) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:32:46.308+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:32:46.312+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:32:46.311+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:32:46.344+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:32:46.362+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:32:46.361+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:32:46.378+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:32:46.377+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:32:46.401+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.106 seconds
[2025-03-10T18:33:34.463+0600] {processor.py:186} INFO - Started process (PID=34278) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:33:34.469+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:33:34.472+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:33:34.472+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:33:34.503+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:33:34.522+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:33:34.521+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:33:34.546+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:33:34.545+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:33:34.579+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.124 seconds
[2025-03-10T18:34:23.983+0600] {processor.py:186} INFO - Started process (PID=34521) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:34:23.987+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:34:23.990+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:34:23.989+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:34:24.022+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:34:24.041+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:34:24.041+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:34:24.263+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:34:24.263+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:34:24.290+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.314 seconds
[2025-03-10T18:35:11.782+0600] {processor.py:186} INFO - Started process (PID=34764) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:35:11.788+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:35:11.791+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:35:11.791+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:35:11.821+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:35:11.838+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:35:11.838+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:35:11.853+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:35:11.853+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:35:11.886+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.112 seconds
[2025-03-10T18:35:55.047+0600] {processor.py:186} INFO - Started process (PID=35012) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:35:55.053+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:35:55.056+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:35:55.055+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:35:55.085+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:35:55.101+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:35:55.101+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:35:55.117+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:35:55.117+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:35:55.141+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.102 seconds
[2025-03-10T18:36:38.372+0600] {processor.py:186} INFO - Started process (PID=35385) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:36:38.378+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:36:38.381+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:36:38.380+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:36:38.413+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:36:38.429+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:36:38.429+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:36:38.446+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:36:38.446+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:36:38.470+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.105 seconds
[2025-03-10T18:37:27.030+0600] {processor.py:186} INFO - Started process (PID=35816) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:37:27.037+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:37:27.048+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:37:27.046+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:37:27.101+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:37:27.135+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:37:27.135+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:37:27.165+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:37:27.165+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:37:27.210+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.211 seconds
[2025-03-10T18:38:19.106+0600] {processor.py:186} INFO - Started process (PID=36382) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:38:19.114+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:38:19.117+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:38:19.116+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:38:19.150+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:38:19.169+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:38:19.168+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:38:19.184+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:38:19.184+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:38:19.215+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.116 seconds
[2025-03-10T18:39:03.045+0600] {processor.py:186} INFO - Started process (PID=36621) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:39:03.052+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:39:03.055+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:39:03.054+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:39:03.085+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:39:03.103+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:39:03.102+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:39:03.118+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:39:03.118+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:39:03.144+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.106 seconds
[2025-03-10T18:39:44.524+0600] {processor.py:186} INFO - Started process (PID=36853) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:39:44.530+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:39:44.533+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:39:44.533+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:39:44.563+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:39:44.580+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:39:44.579+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:39:44.595+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:39:44.595+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:39:44.620+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.104 seconds
[2025-03-10T18:40:26.440+0600] {processor.py:186} INFO - Started process (PID=37087) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:40:26.446+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:40:26.448+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:40:26.448+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:40:26.478+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:40:26.495+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:40:26.495+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:40:26.512+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:40:26.511+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:40:26.535+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.103 seconds
[2025-03-10T18:41:09.707+0600] {processor.py:186} INFO - Started process (PID=37322) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:41:09.713+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:41:09.716+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:41:09.715+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:41:09.745+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:41:09.762+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:41:09.762+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:41:09.777+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:41:09.777+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:41:09.802+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.103 seconds
[2025-03-10T18:41:55.014+0600] {processor.py:186} INFO - Started process (PID=37643) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:41:55.018+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:41:55.020+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:41:55.020+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:41:55.052+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:41:55.069+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:41:55.068+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:41:55.086+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:41:55.085+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:41:55.114+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.108 seconds
[2025-03-10T18:42:43.241+0600] {processor.py:186} INFO - Started process (PID=37929) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:42:43.249+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:42:43.253+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:42:43.252+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:42:43.310+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:42:43.343+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:42:43.343+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:42:43.369+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:42:43.368+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:42:43.394+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.172 seconds
[2025-03-10T18:43:29.818+0600] {processor.py:186} INFO - Started process (PID=38186) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:43:29.824+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:43:29.827+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:43:29.827+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:43:29.859+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:43:29.877+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:43:29.876+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:43:29.893+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:43:29.892+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:43:29.917+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.107 seconds
[2025-03-10T18:44:14.227+0600] {processor.py:186} INFO - Started process (PID=38439) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:44:14.229+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:44:14.232+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:44:14.231+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:44:14.268+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:44:14.289+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:44:14.289+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:44:14.309+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:44:14.308+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:44:14.343+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.126 seconds
[2025-03-10T18:45:02.317+0600] {processor.py:186} INFO - Started process (PID=39157) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:45:02.323+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:45:02.326+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:45:02.325+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:45:02.355+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:45:02.376+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:45:02.376+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:45:02.392+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:45:02.392+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:45:02.420+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.111 seconds
[2025-03-10T18:45:51.657+0600] {processor.py:186} INFO - Started process (PID=39390) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:45:51.665+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:45:51.669+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:45:51.668+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:45:51.704+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:45:51.726+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:45:51.726+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:45:51.746+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:45:51.746+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:45:51.771+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.134 seconds
[2025-03-10T18:46:38.443+0600] {processor.py:186} INFO - Started process (PID=39640) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:46:38.449+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:46:38.452+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:46:38.452+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:46:38.486+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:46:38.505+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:46:38.504+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:46:38.522+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:46:38.522+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:46:38.548+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.115 seconds
[2025-03-10T18:47:27.224+0600] {processor.py:186} INFO - Started process (PID=39897) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:47:27.230+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:47:27.233+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:47:27.232+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:47:27.268+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:47:27.287+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:47:27.286+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:47:27.305+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:47:27.305+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:47:27.332+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.119 seconds
[2025-03-10T18:48:22.316+0600] {processor.py:186} INFO - Started process (PID=40666) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:48:22.319+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:48:22.322+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:48:22.321+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:48:22.354+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:48:22.373+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:48:22.373+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:48:22.389+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:48:22.389+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:48:22.414+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.106 seconds
[2025-03-10T18:49:13.660+0600] {processor.py:186} INFO - Started process (PID=40930) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:49:13.668+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:49:13.671+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:49:13.670+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:49:13.702+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:49:13.719+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:49:13.719+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:49:13.736+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:49:13.735+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:49:13.764+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.111 seconds
[2025-03-10T18:50:03.456+0600] {processor.py:186} INFO - Started process (PID=41154) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:50:03.463+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:50:03.469+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:50:03.467+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:50:03.521+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:50:03.543+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:50:03.543+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:50:03.563+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:50:03.563+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:50:03.591+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.151 seconds
[2025-03-10T18:50:53.289+0600] {processor.py:186} INFO - Started process (PID=41505) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:50:53.291+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:50:53.293+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:50:53.293+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:50:53.341+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:50:53.371+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:50:53.370+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:50:53.396+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:50:53.395+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:50:53.432+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.150 seconds
[2025-03-10T18:51:39.764+0600] {processor.py:186} INFO - Started process (PID=41741) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:51:39.770+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:51:39.773+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:51:39.772+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:51:39.803+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:51:39.820+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:51:39.820+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:51:39.837+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:51:39.837+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:51:39.861+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.104 seconds
[2025-03-10T18:52:23.672+0600] {processor.py:186} INFO - Started process (PID=41973) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:52:23.678+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:52:23.681+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:52:23.681+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:52:23.711+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:52:23.728+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:52:23.728+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:52:23.744+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:52:23.744+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:52:23.771+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.106 seconds
[2025-03-10T18:53:05.970+0600] {processor.py:186} INFO - Started process (PID=42243) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:53:05.971+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:53:05.974+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:53:05.973+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:53:06.005+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:53:06.022+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:53:06.022+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:53:06.038+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:53:06.038+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:53:06.064+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.102 seconds
[2025-03-10T18:53:50.274+0600] {processor.py:186} INFO - Started process (PID=42560) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:53:50.277+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:53:50.285+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:53:50.284+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:53:50.335+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:53:50.363+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:53:50.362+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:53:50.386+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:53:50.386+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:53:50.427+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.168 seconds
[2025-03-10T18:54:41.351+0600] {processor.py:186} INFO - Started process (PID=42831) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:54:41.356+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:54:41.359+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:54:41.358+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:54:41.404+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:54:41.427+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:54:41.426+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:54:41.447+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:54:41.447+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:54:41.477+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.134 seconds
[2025-03-10T18:55:25.555+0600] {processor.py:186} INFO - Started process (PID=43066) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:55:25.560+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:55:25.563+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:55:25.563+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:55:25.594+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:55:25.612+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:55:25.612+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:55:25.628+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:55:25.628+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:55:25.651+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.104 seconds
[2025-03-10T18:56:10.941+0600] {processor.py:186} INFO - Started process (PID=43287) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:56:10.942+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:56:10.945+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:56:10.945+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:56:10.980+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:56:10.999+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:56:10.999+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:56:11.015+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:56:11.015+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:56:11.045+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.113 seconds
[2025-03-10T18:56:58.041+0600] {processor.py:186} INFO - Started process (PID=43552) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:56:58.047+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:56:58.049+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:56:58.049+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:56:58.086+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:56:58.108+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:56:58.108+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:56:58.130+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:56:58.130+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:56:58.169+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.144 seconds
[2025-03-10T18:57:43.714+0600] {processor.py:186} INFO - Started process (PID=43802) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:57:43.721+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:57:43.723+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:57:43.723+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:57:43.761+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:57:43.780+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:57:43.780+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:57:43.798+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:57:43.797+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:57:43.822+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.117 seconds
[2025-03-10T18:58:33.091+0600] {processor.py:186} INFO - Started process (PID=44146) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:58:33.099+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:58:33.107+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:58:33.106+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:58:33.151+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:58:33.167+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:58:33.167+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:58:33.183+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:58:33.183+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:58:33.207+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.142 seconds
[2025-03-10T18:59:20.419+0600] {processor.py:186} INFO - Started process (PID=44425) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:59:20.425+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T18:59:20.430+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:59:20.429+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:59:20.467+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T18:59:20.486+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:59:20.486+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T18:59:20.504+0600] {logging_mixin.py:190} INFO - [2025-03-10T18:59:20.504+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T18:59:20.533+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.140 seconds
[2025-03-10T19:00:09.753+0600] {processor.py:186} INFO - Started process (PID=44672) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:00:09.768+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:00:09.774+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:00:09.774+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:00:09.824+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:00:09.847+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:00:09.847+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:00:09.872+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:00:09.872+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:00:09.915+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.172 seconds
[2025-03-10T19:00:58.130+0600] {processor.py:186} INFO - Started process (PID=45035) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:00:58.137+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:00:58.141+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:00:58.140+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:00:58.195+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:00:58.230+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:00:58.230+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:00:58.253+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:00:58.253+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:00:58.283+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.164 seconds
[2025-03-10T19:01:44.545+0600] {processor.py:186} INFO - Started process (PID=45276) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:01:44.549+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:01:44.555+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:01:44.554+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:01:44.592+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:01:44.612+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:01:44.611+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:01:44.633+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:01:44.632+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:01:44.658+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.126 seconds
[2025-03-10T19:02:30.611+0600] {processor.py:186} INFO - Started process (PID=45571) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:02:30.623+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:02:30.626+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:02:30.626+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:02:30.658+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:02:30.678+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:02:30.678+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:02:30.696+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:02:30.695+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:02:30.733+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.129 seconds
[2025-03-10T19:03:17.666+0600] {processor.py:186} INFO - Started process (PID=45831) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:03:17.673+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:03:17.675+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:03:17.675+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:03:17.705+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:03:17.722+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:03:17.722+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:03:17.739+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:03:17.738+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:03:17.773+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.114 seconds
[2025-03-10T19:04:08.582+0600] {processor.py:186} INFO - Started process (PID=46067) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:04:08.588+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:04:08.591+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:04:08.590+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:04:08.622+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:04:08.638+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:04:08.638+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:04:08.656+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:04:08.655+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:04:08.692+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.117 seconds
[2025-03-10T19:04:58.417+0600] {processor.py:186} INFO - Started process (PID=46326) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:04:58.421+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:04:58.424+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:04:58.423+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:04:58.454+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:04:58.471+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:04:58.471+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:04:58.488+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:04:58.488+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:04:58.512+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.102 seconds
[2025-03-10T19:05:40.645+0600] {processor.py:186} INFO - Started process (PID=46590) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:05:40.646+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:05:40.648+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:05:40.648+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:05:40.683+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:05:40.700+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:05:40.700+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:05:40.723+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:05:40.723+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:05:40.748+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.110 seconds
[2025-03-10T19:06:20.927+0600] {processor.py:186} INFO - Started process (PID=46851) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:06:20.929+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:06:20.932+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:06:20.932+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:06:20.964+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:06:20.982+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:06:20.982+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:06:21.000+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:06:21.000+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:06:21.024+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.104 seconds
[2025-03-10T19:07:07.073+0600] {processor.py:186} INFO - Started process (PID=47141) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:07:07.078+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:07:07.083+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:07:07.082+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:07:07.122+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:07:07.139+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:07:07.139+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:07:07.156+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:07:07.156+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:07:07.180+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.117 seconds
[2025-03-10T19:08:01.636+0600] {processor.py:186} INFO - Started process (PID=47456) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:08:01.638+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:08:01.643+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:08:01.642+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:08:01.682+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:08:01.703+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:08:01.702+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:08:01.727+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:08:01.727+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:08:01.754+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.137 seconds
[2025-03-10T19:08:51.099+0600] {processor.py:186} INFO - Started process (PID=47726) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:08:51.126+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:08:51.129+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:08:51.128+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:08:51.162+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:08:51.181+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:08:51.181+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:08:51.199+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:08:51.198+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:08:51.224+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.134 seconds
[2025-03-10T19:09:40.904+0600] {processor.py:186} INFO - Started process (PID=48011) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:09:40.917+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:09:40.920+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:09:40.919+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:09:40.957+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:09:40.975+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:09:40.974+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:09:40.990+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:09:40.990+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:09:41.014+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.118 seconds
[2025-03-10T19:10:32.133+0600] {processor.py:186} INFO - Started process (PID=48294) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:10:32.139+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:10:32.142+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:10:32.142+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:10:32.183+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:10:32.201+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:10:32.200+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:10:32.218+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:10:32.217+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:10:32.249+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.124 seconds
[2025-03-10T19:11:26.274+0600] {processor.py:186} INFO - Started process (PID=48633) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:11:26.281+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:11:26.283+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:11:26.283+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:11:26.320+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:11:26.339+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:11:26.339+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:11:26.358+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:11:26.358+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:11:26.384+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.119 seconds
[2025-03-10T19:12:15.749+0600] {processor.py:186} INFO - Started process (PID=48903) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:12:15.756+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:12:15.759+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:12:15.758+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:12:15.790+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:12:15.808+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:12:15.808+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:12:15.824+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:12:15.824+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:12:15.849+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.109 seconds
[2025-03-10T19:13:04.230+0600] {processor.py:186} INFO - Started process (PID=49215) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:13:04.236+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:13:04.239+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:13:04.238+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:13:04.270+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:13:04.288+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:13:04.287+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:13:04.305+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:13:04.305+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:13:04.334+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.111 seconds
[2025-03-10T19:13:54.787+0600] {processor.py:186} INFO - Started process (PID=49499) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:13:54.795+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:13:54.798+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:13:54.797+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:13:54.833+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:13:54.852+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:13:54.852+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:13:54.872+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:13:54.872+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:13:54.898+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.123 seconds
[2025-03-10T19:14:48.316+0600] {processor.py:186} INFO - Started process (PID=49781) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:14:48.323+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:14:48.326+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:14:48.326+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:14:48.358+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:14:48.382+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:14:48.381+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:14:48.405+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:14:48.404+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:14:48.448+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.146 seconds
[2025-03-10T19:15:45.171+0600] {processor.py:186} INFO - Started process (PID=50063) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:15:45.179+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:15:45.187+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:15:45.185+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:15:45.254+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:15:45.272+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:15:45.272+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:15:45.290+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:15:45.289+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:15:45.315+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.174 seconds
[2025-03-10T19:16:35.715+0600] {processor.py:186} INFO - Started process (PID=50353) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:16:35.724+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:16:35.733+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:16:35.732+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:16:35.849+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:16:35.891+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:16:35.891+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:16:35.912+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:16:35.911+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:16:35.940+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.249 seconds
[2025-03-10T19:17:23.026+0600] {processor.py:186} INFO - Started process (PID=50630) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:17:23.032+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:17:23.035+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:17:23.035+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:17:23.072+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:17:23.091+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:17:23.091+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:17:23.107+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:17:23.107+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:17:23.147+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.130 seconds
[2025-03-10T19:18:08.704+0600] {processor.py:186} INFO - Started process (PID=50926) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:18:08.729+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:18:08.732+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:18:08.731+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:18:08.765+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:18:08.784+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:18:08.783+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:18:08.800+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:18:08.800+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:18:08.825+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.129 seconds
[2025-03-10T19:18:59.791+0600] {processor.py:186} INFO - Started process (PID=51190) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:18:59.938+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:18:59.942+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:18:59.942+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:18:59.979+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:19:00.130+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:19:00.130+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:19:00.145+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:19:00.145+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:19:00.174+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.393 seconds
[2025-03-10T19:19:55.066+0600] {processor.py:186} INFO - Started process (PID=51471) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:19:55.072+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:19:55.076+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:19:55.075+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:19:55.109+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:19:55.128+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:19:55.127+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:19:55.145+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:19:55.145+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:19:55.314+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.256 seconds
[2025-03-10T19:20:45.166+0600] {processor.py:186} INFO - Started process (PID=51719) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:20:45.171+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:20:45.174+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:20:45.173+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:20:45.208+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:20:45.227+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:20:45.226+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:20:45.245+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:20:45.244+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:20:45.270+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.112 seconds
[2025-03-10T19:21:32.776+0600] {processor.py:186} INFO - Started process (PID=52008) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:21:32.778+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:21:32.784+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:21:32.783+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:21:32.825+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:21:32.845+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:21:32.845+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:21:32.866+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:21:32.866+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:21:32.892+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.133 seconds
[2025-03-10T19:22:05.216+0600] {processor.py:186} INFO - Started process (PID=52237) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:22:05.217+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:22:05.222+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:22:05.221+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:22:05.261+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:22:05.286+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:22:05.286+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:22:05.307+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:22:05.307+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:22:05.336+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.132 seconds
[2025-03-10T19:23:31.306+0600] {processor.py:186} INFO - Started process (PID=52578) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:23:31.313+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:23:31.316+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:23:31.315+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:23:31.349+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:23:31.368+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:23:31.368+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:23:31.385+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:23:31.385+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:23:31.420+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.126 seconds
[2025-03-10T19:24:23.391+0600] {processor.py:186} INFO - Started process (PID=52839) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:24:23.398+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:24:23.401+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:24:23.400+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:24:23.434+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:24:23.454+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:24:23.453+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:24:23.473+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:24:23.472+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:24:23.500+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.116 seconds
[2025-03-10T19:25:10.938+0600] {processor.py:186} INFO - Started process (PID=53126) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:25:10.940+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:25:10.945+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:25:10.944+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:25:10.994+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:25:11.020+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:25:11.020+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:25:11.042+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:25:11.042+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:25:11.069+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.152 seconds
[2025-03-10T19:25:44.496+0600] {processor.py:186} INFO - Started process (PID=53387) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:25:44.498+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:25:44.502+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:25:44.502+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:25:44.540+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:25:44.762+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:25:44.762+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:25:44.793+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:25:44.793+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:25:44.852+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.365 seconds
[2025-03-10T19:27:03.275+0600] {processor.py:186} INFO - Started process (PID=53672) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:27:03.279+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:27:03.283+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:27:03.282+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:27:03.322+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:27:03.342+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:27:03.341+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:27:03.361+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:27:03.360+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:27:03.388+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.123 seconds
[2025-03-10T19:27:46.886+0600] {processor.py:186} INFO - Started process (PID=53937) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:27:46.893+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:27:46.896+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:27:46.896+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:27:46.933+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:27:46.952+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:27:46.952+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:27:46.970+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:27:46.970+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:27:47.003+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.129 seconds
[2025-03-10T19:28:31.518+0600] {processor.py:186} INFO - Started process (PID=54170) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:28:31.519+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:28:31.523+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:28:31.522+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:28:31.557+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:28:31.578+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:28:31.578+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:28:31.598+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:28:31.597+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:28:31.627+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.118 seconds
[2025-03-10T19:29:19.248+0600] {processor.py:186} INFO - Started process (PID=54391) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:29:19.262+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:29:19.272+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:29:19.270+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:29:19.314+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:29:19.332+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:29:19.332+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:29:19.350+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:29:19.350+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:29:19.374+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.135 seconds
[2025-03-10T19:30:09.692+0600] {processor.py:186} INFO - Started process (PID=54618) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:30:09.699+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:30:09.702+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:30:09.701+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:30:09.736+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:30:09.757+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:30:09.757+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:30:09.778+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:30:09.778+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:30:09.820+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.137 seconds
[2025-03-10T19:30:57.223+0600] {processor.py:186} INFO - Started process (PID=54845) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:30:57.230+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:30:57.233+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:30:57.232+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:30:57.265+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:30:57.283+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:30:57.283+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:30:57.301+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:30:57.300+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:30:57.337+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.122 seconds
[2025-03-10T19:31:44.918+0600] {processor.py:186} INFO - Started process (PID=55067) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:31:44.924+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:31:44.927+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:31:44.926+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:31:44.960+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:31:44.979+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:31:44.979+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:31:44.998+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:31:44.997+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:31:45.034+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.125 seconds
[2025-03-10T19:32:31.544+0600] {processor.py:186} INFO - Started process (PID=55303) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:32:31.546+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:32:31.551+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:32:31.550+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:32:31.595+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:32:31.619+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:32:31.619+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:32:31.641+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:32:31.640+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:32:31.681+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.147 seconds
[2025-03-10T19:33:21.625+0600] {processor.py:186} INFO - Started process (PID=55611) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:33:21.634+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:33:21.644+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:33:21.642+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:33:21.742+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:33:21.772+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:33:21.772+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:33:21.791+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:33:21.790+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:33:21.836+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.245 seconds
[2025-03-10T19:34:12.874+0600] {processor.py:186} INFO - Started process (PID=55854) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:34:12.881+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:34:12.887+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:34:12.886+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:34:12.937+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:34:12.960+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:34:12.960+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:34:12.980+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:34:12.980+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:34:13.019+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.163 seconds
[2025-03-10T19:35:01.094+0600] {processor.py:186} INFO - Started process (PID=56078) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:35:01.124+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:35:01.136+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:35:01.132+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:35:01.222+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:35:01.247+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:35:01.247+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:35:01.270+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:35:01.270+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:35:01.326+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.259 seconds
[2025-03-10T19:35:51.605+0600] {processor.py:186} INFO - Started process (PID=56301) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:35:51.615+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:35:51.633+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:35:51.632+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:35:51.701+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:35:51.743+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:35:51.742+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:35:51.776+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:35:51.776+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:35:51.835+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.274 seconds
[2025-03-10T19:36:47.096+0600] {processor.py:186} INFO - Started process (PID=56525) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:36:47.103+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:36:47.106+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:36:47.105+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:36:47.142+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:36:47.162+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:36:47.162+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:36:47.182+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:36:47.182+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:36:47.221+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.133 seconds
[2025-03-10T19:37:42.452+0600] {processor.py:186} INFO - Started process (PID=56750) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:37:42.466+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:37:42.472+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:37:42.471+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:37:42.530+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:37:42.553+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:37:42.553+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:37:42.573+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:37:42.573+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:37:42.604+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.169 seconds
[2025-03-10T19:38:31.879+0600] {processor.py:186} INFO - Started process (PID=57019) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:38:31.885+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:38:31.890+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:38:31.889+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:38:31.927+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:38:31.950+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:38:31.949+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:38:31.969+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:38:31.969+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:38:32.039+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.172 seconds
[2025-03-10T19:39:26.893+0600] {processor.py:186} INFO - Started process (PID=57242) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:39:26.899+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:39:26.902+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:39:26.902+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:39:26.939+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:39:26.958+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:39:26.958+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:39:26.977+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:39:26.977+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:39:27.013+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.129 seconds
[2025-03-10T19:40:19.656+0600] {processor.py:186} INFO - Started process (PID=57482) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:40:19.663+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:40:19.668+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:40:19.667+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:40:19.719+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:40:19.743+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:40:19.743+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:40:19.765+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:40:19.765+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:40:19.810+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.168 seconds
[2025-03-10T19:41:13.804+0600] {processor.py:186} INFO - Started process (PID=57706) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:41:13.809+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:41:13.817+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:41:13.816+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:41:13.873+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:41:13.892+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:41:13.892+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:41:13.910+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:41:13.910+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:41:13.933+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.154 seconds
[2025-03-10T19:42:02.763+0600] {processor.py:186} INFO - Started process (PID=57926) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:42:02.769+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:42:02.773+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:42:02.772+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:42:02.810+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:42:02.832+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:42:02.832+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:42:02.858+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:42:02.858+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:42:02.886+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.132 seconds
[2025-03-10T19:42:53.957+0600] {processor.py:186} INFO - Started process (PID=58198) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:42:53.963+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:42:53.967+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:42:53.966+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:42:54.000+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:42:54.021+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:42:54.020+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:42:54.040+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:42:54.040+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:42:54.067+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.118 seconds
[2025-03-10T19:43:46.069+0600] {processor.py:186} INFO - Started process (PID=58458) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:43:46.070+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:43:46.076+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:43:46.074+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:43:46.121+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:43:46.146+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:43:46.146+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:43:46.172+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:43:46.172+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:43:46.249+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.196 seconds
[2025-03-10T19:44:37.362+0600] {processor.py:186} INFO - Started process (PID=58722) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:44:37.366+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:44:37.374+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:44:37.371+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:44:37.426+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:44:37.451+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:44:37.450+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:44:37.476+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:44:37.476+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:44:37.510+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.167 seconds
[2025-03-10T19:45:24.221+0600] {processor.py:186} INFO - Started process (PID=58983) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:45:24.228+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:45:24.231+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:45:24.230+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:45:24.265+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:45:24.285+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:45:24.284+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:45:24.302+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:45:24.302+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:45:24.327+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.115 seconds
[2025-03-10T19:46:09.609+0600] {processor.py:186} INFO - Started process (PID=59222) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:46:09.615+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:46:09.619+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:46:09.618+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:46:09.659+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:46:09.680+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:46:09.679+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:46:09.702+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:46:09.702+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:46:09.743+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.147 seconds
[2025-03-10T19:46:57.494+0600] {processor.py:186} INFO - Started process (PID=59443) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:46:57.497+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:46:57.500+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:46:57.499+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:46:57.548+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:46:57.575+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:46:57.575+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:46:57.606+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:46:57.606+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:46:57.652+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.167 seconds
[2025-03-10T19:47:54.021+0600] {processor.py:186} INFO - Started process (PID=59695) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:47:54.028+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:47:54.033+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:47:54.032+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:47:54.081+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:47:54.109+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:47:54.108+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:47:54.136+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:47:54.136+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:47:54.192+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.186 seconds
[2025-03-10T19:48:44.551+0600] {processor.py:186} INFO - Started process (PID=59919) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:48:44.553+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:48:44.556+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:48:44.555+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:48:44.594+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:48:44.615+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:48:44.615+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:48:44.636+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:48:44.636+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:48:44.663+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.125 seconds
[2025-03-10T19:49:37.303+0600] {processor.py:186} INFO - Started process (PID=60167) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:49:37.310+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:49:37.317+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:49:37.316+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:49:37.367+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:49:37.393+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:49:37.393+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:49:37.415+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:49:37.415+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:49:37.456+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.167 seconds
[2025-03-10T19:50:35.545+0600] {processor.py:186} INFO - Started process (PID=60392) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:50:35.551+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:50:35.555+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:50:35.554+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:50:35.587+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:50:35.606+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:50:35.606+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:50:35.624+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:50:35.624+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:50:35.665+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.129 seconds
[2025-03-10T19:51:21.840+0600] {processor.py:186} INFO - Started process (PID=60613) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:51:21.856+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:51:21.860+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:51:21.859+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:51:21.902+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:51:21.923+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:51:21.923+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:51:21.948+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:51:21.948+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:51:21.985+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.159 seconds
[2025-03-10T19:52:11.483+0600] {processor.py:186} INFO - Started process (PID=60848) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:52:11.487+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:52:11.491+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:52:11.491+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:52:11.535+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:52:11.561+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:52:11.561+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:52:11.585+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:52:11.585+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:52:11.619+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.148 seconds
[2025-03-10T19:53:02.312+0600] {processor.py:186} INFO - Started process (PID=61124) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:53:02.319+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:53:02.324+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:53:02.323+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:53:02.363+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:53:02.383+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:53:02.382+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:53:02.406+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:53:02.405+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:53:02.452+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.149 seconds
[2025-03-10T19:53:55.048+0600] {processor.py:186} INFO - Started process (PID=61386) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:53:55.054+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:53:55.058+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:53:55.057+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:53:55.098+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:53:55.121+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:53:55.121+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:53:55.143+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:53:55.142+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:53:55.182+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.157 seconds
[2025-03-10T19:54:49.335+0600] {processor.py:186} INFO - Started process (PID=61628) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:54:49.341+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:54:49.344+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:54:49.344+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:54:49.377+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:54:49.397+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:54:49.397+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:54:49.415+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:54:49.415+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:54:49.450+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.123 seconds
[2025-03-10T19:55:42.989+0600] {processor.py:186} INFO - Started process (PID=61855) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:55:43.007+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:55:43.012+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:55:43.011+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:55:43.059+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:55:43.094+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:55:43.093+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:55:43.123+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:55:43.122+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:55:43.180+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.208 seconds
[2025-03-10T19:56:34.486+0600] {processor.py:186} INFO - Started process (PID=62111) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:56:34.493+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:56:34.496+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:56:34.496+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:56:34.533+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:56:34.555+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:56:34.555+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:56:34.576+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:56:34.575+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:56:34.605+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.129 seconds
[2025-03-10T19:57:26.553+0600] {processor.py:186} INFO - Started process (PID=62376) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:57:26.560+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:57:26.564+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:57:26.563+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:57:26.600+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:57:26.624+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:57:26.624+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:57:26.645+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:57:26.644+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:57:26.674+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.131 seconds
[2025-03-10T19:58:16.384+0600] {processor.py:186} INFO - Started process (PID=62669) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:58:16.391+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:58:16.393+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:58:16.393+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:58:16.433+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:58:16.453+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:58:16.453+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:58:16.471+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:58:16.471+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:58:16.496+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.119 seconds
[2025-03-10T19:59:08.055+0600] {processor.py:186} INFO - Started process (PID=62930) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:59:08.061+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T19:59:08.064+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:59:08.064+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:59:08.096+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T19:59:08.115+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:59:08.114+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T19:59:08.132+0600] {logging_mixin.py:190} INFO - [2025-03-10T19:59:08.132+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T19:59:08.158+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.113 seconds
[2025-03-10T20:00:00.715+0600] {processor.py:186} INFO - Started process (PID=63191) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:00:00.717+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:00:00.720+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:00:00.720+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:00:00.758+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:00:00.782+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:00:00.781+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:00:00.803+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:00:00.803+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:00:00.829+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.126 seconds
[2025-03-10T20:00:58.453+0600] {processor.py:186} INFO - Started process (PID=63451) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:00:58.460+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:00:58.465+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:00:58.464+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:00:58.516+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:00:58.545+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:00:58.544+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:00:58.573+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:00:58.572+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:00:58.652+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.212 seconds
[2025-03-10T20:02:01.291+0600] {processor.py:186} INFO - Started process (PID=63729) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:02:01.298+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:02:01.302+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:02:01.300+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:02:01.336+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:02:01.356+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:02:01.356+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:02:01.377+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:02:01.377+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:02:01.416+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.134 seconds
[2025-03-10T20:02:58.422+0600] {processor.py:186} INFO - Started process (PID=64027) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:02:58.431+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:02:58.439+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:02:58.437+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:02:58.486+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:02:58.509+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:02:58.509+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:02:58.534+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:02:58.534+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:02:58.579+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.187 seconds
[2025-03-10T20:03:52.911+0600] {processor.py:186} INFO - Started process (PID=64288) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:03:52.917+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:03:52.920+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:03:52.920+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:03:52.956+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:03:52.975+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:03:52.975+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:03:52.994+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:03:52.994+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:03:53.031+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.129 seconds
[2025-03-10T20:04:50.727+0600] {processor.py:186} INFO - Started process (PID=64553) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:04:50.730+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:04:50.735+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:04:50.735+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:04:50.775+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:04:50.802+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:04:50.802+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:04:50.825+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:04:50.825+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:04:50.859+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.145 seconds
[2025-03-10T20:05:48.922+0600] {processor.py:186} INFO - Started process (PID=64821) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:05:48.928+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:05:48.932+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:05:48.931+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:05:48.965+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:05:48.983+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:05:48.983+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:05:49.000+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:05:49.000+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:05:49.027+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.114 seconds
[2025-03-10T20:06:41.051+0600] {processor.py:186} INFO - Started process (PID=65075) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:06:41.058+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:06:41.064+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:06:41.063+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:06:41.105+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:06:41.132+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:06:41.132+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:06:41.156+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:06:41.156+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:06:41.191+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.156 seconds
[2025-03-10T20:07:30.198+0600] {processor.py:186} INFO - Started process (PID=65327) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:07:30.204+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:07:30.207+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:07:30.207+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:07:30.242+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:07:30.261+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:07:30.261+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:07:30.279+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:07:30.279+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:07:30.306+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.116 seconds
[2025-03-10T20:08:18.351+0600] {processor.py:186} INFO - Started process (PID=65591) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:08:18.356+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:08:18.358+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:08:18.358+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:08:18.397+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:08:18.415+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:08:18.415+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:08:18.433+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:08:18.433+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:08:18.459+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.115 seconds
[2025-03-10T20:09:08.974+0600] {processor.py:186} INFO - Started process (PID=65814) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:09:08.981+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:09:08.984+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:09:08.983+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:09:09.017+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:09:09.036+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:09:09.036+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:09:09.053+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:09:09.053+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:09:09.079+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.112 seconds
[2025-03-10T20:10:01.561+0600] {processor.py:186} INFO - Started process (PID=66084) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:10:01.594+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:10:01.597+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:10:01.597+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:10:01.635+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:10:01.657+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:10:01.657+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:10:01.678+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:10:01.678+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:10:01.706+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.153 seconds
[2025-03-10T20:10:50.324+0600] {processor.py:186} INFO - Started process (PID=66364) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:10:50.326+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:10:50.331+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:10:50.330+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:10:50.381+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:10:50.410+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:10:50.410+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:10:50.437+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:10:50.436+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:10:50.468+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.158 seconds
[2025-03-10T20:11:38.978+0600] {processor.py:186} INFO - Started process (PID=66638) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:11:38.985+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:11:38.988+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:11:38.987+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:11:39.025+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:11:39.048+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:11:39.048+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:11:39.069+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:11:39.069+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:11:39.108+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.138 seconds
[2025-03-10T20:12:30.500+0600] {processor.py:186} INFO - Started process (PID=66938) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:12:30.503+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:12:30.508+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:12:30.507+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:12:30.560+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:12:30.590+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:12:30.590+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:12:30.630+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:12:30.630+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:12:30.670+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.183 seconds
[2025-03-10T20:13:32.927+0600] {processor.py:186} INFO - Started process (PID=67232) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:13:32.934+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:13:32.938+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:13:32.937+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:13:33.037+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:13:33.067+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:13:33.066+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:13:33.102+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:13:33.102+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:13:33.149+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.232 seconds
[2025-03-10T20:14:44.590+0600] {processor.py:186} INFO - Started process (PID=67552) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:14:44.592+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:14:44.596+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:14:44.595+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:14:44.641+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:14:44.665+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:14:44.665+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:14:44.690+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:14:44.690+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:14:44.726+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.150 seconds
[2025-03-10T20:15:51.332+0600] {processor.py:186} INFO - Started process (PID=67842) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:15:51.337+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:15:51.346+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:15:51.344+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:15:51.408+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:15:51.428+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:15:51.427+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:15:51.455+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:15:51.455+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:15:51.487+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.182 seconds
[2025-03-10T20:16:56.633+0600] {processor.py:186} INFO - Started process (PID=68116) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:16:56.641+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:16:56.649+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:16:56.648+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:16:56.702+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:16:56.732+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:16:56.731+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:16:56.757+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:16:56.757+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:16:56.812+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.201 seconds
[2025-03-10T20:17:57.544+0600] {processor.py:186} INFO - Started process (PID=68437) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:17:57.560+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:17:57.564+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:17:57.563+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:17:57.608+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:17:57.630+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:17:57.629+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:17:57.653+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:17:57.652+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:17:57.678+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.153 seconds
[2025-03-10T20:18:59.038+0600] {processor.py:186} INFO - Started process (PID=68704) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:18:59.045+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:18:59.049+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:18:59.048+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:18:59.089+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:18:59.113+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:18:59.113+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:18:59.135+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:18:59.134+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:18:59.174+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.151 seconds
[2025-03-10T20:20:05.302+0600] {processor.py:186} INFO - Started process (PID=68987) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:20:05.309+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:20:05.314+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:20:05.313+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:20:05.378+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:20:05.415+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:20:05.414+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:20:05.446+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:20:05.445+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:20:05.524+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.234 seconds
[2025-03-10T20:21:02.766+0600] {processor.py:186} INFO - Started process (PID=69260) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:21:02.773+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:21:02.778+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:21:02.777+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:21:02.846+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:21:02.893+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:21:02.893+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:21:02.939+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:21:02.938+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:21:03.035+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.290 seconds
[2025-03-10T20:22:08.538+0600] {processor.py:186} INFO - Started process (PID=69546) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:22:08.552+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:22:08.556+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:22:08.555+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:22:08.601+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:22:08.622+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:22:08.621+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:22:08.643+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:22:08.643+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:22:08.670+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.153 seconds
[2025-03-10T20:23:08.456+0600] {processor.py:186} INFO - Started process (PID=69847) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:23:08.465+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:23:08.478+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:23:08.477+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:23:08.578+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:23:08.714+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:23:08.713+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:23:08.826+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:23:08.825+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:23:09.076+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.638 seconds
[2025-03-10T20:24:05.547+0600] {processor.py:186} INFO - Started process (PID=70120) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:24:05.554+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:24:05.581+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:24:05.577+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:24:05.658+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:24:05.690+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:24:05.690+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:24:05.729+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:24:05.729+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:24:05.794+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.263 seconds
[2025-03-10T20:25:09.303+0600] {processor.py:186} INFO - Started process (PID=70395) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:25:09.306+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:25:09.312+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:25:09.311+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:25:09.432+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:25:09.489+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:25:09.488+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:25:09.544+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:25:09.544+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:25:09.672+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.384 seconds
[2025-03-10T20:26:20.126+0600] {processor.py:186} INFO - Started process (PID=70678) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:26:20.131+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:26:20.136+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:26:20.135+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:26:20.176+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:26:20.198+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:26:20.198+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:26:20.226+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:26:20.225+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:26:20.264+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.151 seconds
[2025-03-10T20:27:27.712+0600] {processor.py:186} INFO - Started process (PID=70974) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:27:27.720+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:27:27.727+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:27:27.726+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:27:27.772+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:27:27.800+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:27:27.800+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:27:27.823+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:27:27.822+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:27:27.868+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.173 seconds
[2025-03-10T20:28:21.843+0600] {processor.py:186} INFO - Started process (PID=71273) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:28:21.846+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:28:21.852+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:28:21.851+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:28:21.957+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:28:21.937+0600] {dagbag.py:387} ERROR - Failed to import: /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
Traceback (most recent call last):
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py", line 134, in <module>
    task_load_clean_data_into_postgres=PythonOperator(
                                       ^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'load_clean_data_into pg_task' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-03-10T20:28:21.961+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:28:22.011+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.183 seconds
[2025-03-10T20:29:25.403+0600] {processor.py:186} INFO - Started process (PID=71506) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:29:25.410+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:29:25.412+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:29:25.411+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:29:25.449+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:29:25.444+0600] {dagbag.py:387} ERROR - Failed to import: /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
Traceback (most recent call last):
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py", line 134, in <module>
    task_load_clean_data_into_postgres=PythonOperator(
                                       ^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'load_clean_data_into pg_task' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-03-10T20:29:25.450+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:29:25.473+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.081 seconds
[2025-03-10T20:30:18.166+0600] {processor.py:186} INFO - Started process (PID=71744) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:30:18.174+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:30:18.177+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:30:18.176+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:30:18.224+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:30:18.220+0600] {dagbag.py:387} ERROR - Failed to import: /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
Traceback (most recent call last):
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py", line 134, in <module>
    task_load_clean_data_into_postgres=PythonOperator(
                                       ^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'load_clean_data_into pg_task' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-03-10T20:30:18.226+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:30:18.263+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.115 seconds
[2025-03-10T20:31:08.715+0600] {processor.py:186} INFO - Started process (PID=71983) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:31:08.721+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:31:08.723+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:31:08.723+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:31:08.756+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:31:08.753+0600] {dagbag.py:387} ERROR - Failed to import: /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
Traceback (most recent call last):
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py", line 134, in <module>
    task_load_clean_data_into_postgres=PythonOperator(
                                       ^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'load_clean_data_into pg_task' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-03-10T20:31:08.757+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:31:08.788+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.082 seconds
[2025-03-10T20:32:01.447+0600] {processor.py:186} INFO - Started process (PID=72231) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:32:01.449+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:32:01.450+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:32:01.450+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:32:01.490+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:32:01.487+0600] {dagbag.py:387} ERROR - Failed to import: /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
Traceback (most recent call last):
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py", line 134, in <module>
    task_load_clean_data_into_postgres=PythonOperator(
                                       ^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'load_clean_data_into pg_task' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-03-10T20:32:01.492+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:32:01.528+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.090 seconds
[2025-03-10T20:32:53.094+0600] {processor.py:186} INFO - Started process (PID=72515) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:32:53.110+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:32:53.112+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:32:53.111+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:32:53.146+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:32:53.143+0600] {dagbag.py:387} ERROR - Failed to import: /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
Traceback (most recent call last):
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py", line 134, in <module>
    task_load_clean_data_into_postgres=PythonOperator(
                                       ^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'load_clean_data_into pg_task' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-03-10T20:32:53.147+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:32:53.168+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.086 seconds
[2025-03-10T20:33:46.262+0600] {processor.py:186} INFO - Started process (PID=72765) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:33:46.268+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:33:46.271+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:33:46.270+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:33:46.531+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:33:46.526+0600] {dagbag.py:387} ERROR - Failed to import: /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
Traceback (most recent call last):
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py", line 134, in <module>
    task_load_clean_data_into_postgres=PythonOperator(
                                       ^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'load_clean_data_into pg_task' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-03-10T20:33:46.532+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:33:46.548+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.300 seconds
[2025-03-10T20:34:36.220+0600] {processor.py:186} INFO - Started process (PID=73009) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:34:36.223+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:34:36.225+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:34:36.224+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:34:36.258+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:34:36.255+0600] {dagbag.py:387} ERROR - Failed to import: /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
Traceback (most recent call last):
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py", line 136, in <module>
    task_load_clean_data_into_postgres=PythonOperator(
                                       ^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'load_clean_data_into pg_task' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-03-10T20:34:36.259+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:34:36.278+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.067 seconds
[2025-03-10T20:35:21.024+0600] {processor.py:186} INFO - Started process (PID=73271) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:35:21.025+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:35:21.027+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:35:21.026+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:35:21.057+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:35:21.054+0600] {dagbag.py:387} ERROR - Failed to import: /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
Traceback (most recent call last):
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py", line 136, in <module>
    task_load_clean_data_into_postgres=PythonOperator(
                                       ^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/shamim/airflow_venv/lib/python3.12/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'load_clean_data_into pg_task' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-03-10T20:35:21.058+0600] {processor.py:927} WARNING - No viable dags retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:35:21.076+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.060 seconds
[2025-03-10T20:36:08.587+0600] {processor.py:186} INFO - Started process (PID=73506) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:36:08.594+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:36:08.596+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:36:08.595+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:36:08.639+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:36:08.816+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:36:08.816+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:36:08.832+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:36:08.832+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:36:08.861+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.283 seconds
[2025-03-10T20:36:53.532+0600] {processor.py:186} INFO - Started process (PID=73717) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:36:53.536+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:36:53.539+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:36:53.537+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:36:53.592+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:36:53.857+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:36:53.857+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:36:53.876+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:36:53.875+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:36:53.925+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.403 seconds
[2025-03-10T20:38:05.399+0600] {processor.py:186} INFO - Started process (PID=74006) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:38:05.406+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:38:05.408+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:38:05.408+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:38:05.459+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:38:05.642+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:38:05.641+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:38:05.668+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:38:05.668+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:38:05.694+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.304 seconds
[2025-03-10T20:38:55.252+0600] {processor.py:186} INFO - Started process (PID=74266) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:38:55.261+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:38:55.270+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:38:55.268+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:38:55.336+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:38:55.357+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:38:55.356+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:38:55.373+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:38:55.373+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:38:55.400+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.177 seconds
[2025-03-10T20:39:46.687+0600] {processor.py:186} INFO - Started process (PID=74492) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:39:46.693+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:39:46.695+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:39:46.694+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:39:46.728+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:39:46.875+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:39:46.875+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:39:46.890+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:39:46.890+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:39:46.918+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.239 seconds
[2025-03-10T20:40:36.807+0600] {processor.py:186} INFO - Started process (PID=74745) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:40:36.813+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:40:36.815+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:40:36.814+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:40:36.854+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:40:37.033+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:40:37.033+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:40:37.051+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:40:37.050+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:40:37.079+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.283 seconds
[2025-03-10T20:40:50.438+0600] {processor.py:186} INFO - Started process (PID=74943) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:40:50.440+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:40:50.442+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:40:50.442+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:40:50.493+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:40:50.502+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:40:50.502+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:40:50.523+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:40:50.523+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:40:50.558+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.131 seconds
[2025-03-10T20:41:33.701+0600] {processor.py:186} INFO - Started process (PID=74991) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:41:33.707+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:41:33.709+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:41:33.708+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:41:33.742+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:41:33.763+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:41:33.762+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:41:33.780+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:41:33.780+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:41:33.816+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.123 seconds
[2025-03-10T20:42:21.343+0600] {processor.py:186} INFO - Started process (PID=75263) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:42:21.350+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:42:21.352+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:42:21.351+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:42:21.398+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:42:21.419+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:42:21.419+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:42:21.441+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:42:21.441+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:42:21.472+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.138 seconds
[2025-03-10T20:42:35.116+0600] {processor.py:186} INFO - Started process (PID=75472) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:42:35.119+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:42:35.123+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:42:35.122+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:42:35.186+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:42:35.209+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:42:35.209+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:42:35.226+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:42:35.226+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:42:35.251+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.155 seconds
[2025-03-10T20:43:17.400+0600] {processor.py:186} INFO - Started process (PID=75583) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:43:17.407+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:43:17.408+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:43:17.408+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:43:17.441+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:43:17.460+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:43:17.460+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:43:17.476+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:43:17.476+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:43:17.510+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.117 seconds
[2025-03-10T20:44:07.238+0600] {processor.py:186} INFO - Started process (PID=75877) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:44:07.244+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:44:07.246+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:44:07.245+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:44:07.278+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:44:07.422+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:44:07.421+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:44:07.436+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:44:07.435+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:44:07.466+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.236 seconds
[2025-03-10T20:44:52.773+0600] {processor.py:186} INFO - Started process (PID=76143) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:44:52.779+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:44:52.781+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:44:52.780+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:44:52.814+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:44:52.836+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:44:52.836+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:44:52.855+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:44:52.855+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:44:52.883+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.119 seconds
[2025-03-10T20:45:20.950+0600] {processor.py:186} INFO - Started process (PID=76389) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:45:20.952+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:45:20.954+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:45:20.953+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:45:21.000+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:45:21.249+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:45:21.248+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:45:21.280+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:45:21.280+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:45:21.329+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.391 seconds
[2025-03-10T20:46:39.942+0600] {processor.py:186} INFO - Started process (PID=76689) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:46:39.946+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:46:39.948+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:46:39.948+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:46:39.984+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:46:40.134+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:46:40.133+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:46:40.149+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:46:40.148+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:46:40.175+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.240 seconds
[2025-03-10T20:47:24.330+0600] {processor.py:186} INFO - Started process (PID=76956) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:47:24.343+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:47:24.348+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:47:24.346+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:47:24.430+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:47:24.596+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:47:24.595+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:47:24.614+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:47:24.613+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:47:24.651+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.345 seconds
[2025-03-10T20:48:00.583+0600] {processor.py:186} INFO - Started process (PID=77228) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:48:00.584+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:48:00.589+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:48:00.586+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:48:00.653+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:48:00.863+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:48:00.862+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:48:00.882+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:48:00.882+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:48:00.920+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.358 seconds
[2025-03-10T20:49:09.802+0600] {processor.py:186} INFO - Started process (PID=77501) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:49:09.809+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:49:09.812+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:49:09.810+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:49:09.882+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:49:10.038+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:49:10.038+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:49:10.055+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:49:10.055+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:49:10.078+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.292 seconds
[2025-03-10T20:50:06.937+0600] {processor.py:186} INFO - Started process (PID=77761) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:50:06.944+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:50:06.946+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:50:06.945+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:50:06.992+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:50:07.019+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:50:07.019+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:50:07.040+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:50:07.040+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:50:07.077+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.152 seconds
[2025-03-10T20:51:04.047+0600] {processor.py:186} INFO - Started process (PID=78151) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:51:04.074+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:51:04.076+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:51:04.075+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:51:04.120+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:51:04.325+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:51:04.325+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:51:04.348+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:51:04.348+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:51:04.402+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.364 seconds
[2025-03-10T20:52:06.066+0600] {processor.py:186} INFO - Started process (PID=78592) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:52:06.083+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:52:06.088+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:52:06.086+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:52:06.148+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:52:06.168+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:52:06.168+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:52:06.186+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:52:06.186+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:52:06.212+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.163 seconds
[2025-03-10T20:52:33.797+0600] {processor.py:186} INFO - Started process (PID=78820) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:52:33.799+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:52:33.801+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:52:33.800+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:52:33.858+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:52:33.885+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:52:33.885+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:52:33.916+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:52:33.915+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:52:33.960+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.223 seconds
[2025-03-10T20:53:08.932+0600] {processor.py:186} INFO - Started process (PID=78900) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:53:08.943+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:53:08.946+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:53:08.945+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:53:09.007+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:53:09.034+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:53:09.034+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:53:09.059+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:53:09.058+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:53:09.092+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.184 seconds
[2025-03-10T20:54:11.605+0600] {processor.py:186} INFO - Started process (PID=79150) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:54:11.607+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:54:11.609+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:54:11.609+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:54:11.648+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:54:11.828+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:54:11.828+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:54:11.846+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:54:11.846+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:54:11.880+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.286 seconds
[2025-03-10T20:54:33.893+0600] {processor.py:186} INFO - Started process (PID=79363) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:54:33.894+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:54:33.896+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:54:33.896+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:54:33.933+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:54:33.944+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:54:33.943+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:54:33.974+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:54:33.973+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:54:34.009+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.128 seconds
[2025-03-10T20:55:27.557+0600] {processor.py:186} INFO - Started process (PID=79451) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:55:27.563+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:55:27.565+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:55:27.564+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:55:27.596+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:55:27.733+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:55:27.732+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:55:27.747+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:55:27.747+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:55:27.786+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.238 seconds
[2025-03-10T20:56:15.996+0600] {processor.py:186} INFO - Started process (PID=79694) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:56:16.011+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:56:16.017+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:56:16.015+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:56:16.108+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:56:16.134+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:56:16.133+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:56:16.151+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:56:16.150+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:56:16.179+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.214 seconds
[2025-03-10T20:57:02.264+0600] {processor.py:186} INFO - Started process (PID=79957) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:57:02.268+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:57:02.275+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:57:02.270+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:57:02.397+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:57:02.501+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:57:02.500+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:57:02.593+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:57:02.593+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:57:02.681+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.443 seconds
[2025-03-10T20:58:33.589+0600] {processor.py:186} INFO - Started process (PID=80305) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:58:33.594+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:58:33.596+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:58:33.595+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:58:33.639+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:58:33.814+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:58:33.814+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:58:33.833+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:58:33.832+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:58:33.863+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.285 seconds
[2025-03-10T20:59:27.519+0600] {processor.py:186} INFO - Started process (PID=80572) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:59:27.522+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:59:27.524+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:59:27.524+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:59:27.559+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:59:27.699+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:59:27.699+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:59:27.714+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:59:27.713+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:59:27.738+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.228 seconds
[2025-03-10T20:59:43.836+0600] {processor.py:186} INFO - Started process (PID=80773) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:59:43.841+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T20:59:43.845+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:59:43.845+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:59:43.938+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T20:59:43.950+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:59:43.950+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T20:59:43.977+0600] {logging_mixin.py:190} INFO - [2025-03-10T20:59:43.976+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T20:59:44.013+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.200 seconds
[2025-03-10T21:00:54.560+0600] {processor.py:186} INFO - Started process (PID=80966) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:00:54.563+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:00:54.566+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:00:54.565+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:00:54.641+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:00:54.682+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:00:54.681+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:00:54.750+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:00:54.747+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:00:54.835+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.307 seconds
[2025-03-10T21:02:17.071+0600] {processor.py:186} INFO - Started process (PID=81349) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:02:17.077+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:02:17.079+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:02:17.078+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:02:17.117+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:02:17.139+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:02:17.139+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:02:17.159+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:02:17.159+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:02:17.193+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.138 seconds
[2025-03-10T21:03:03.696+0600] {processor.py:186} INFO - Started process (PID=81591) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:03:03.703+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:03:03.706+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:03:03.704+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:03:03.751+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:03:03.777+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:03:03.776+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:03:03.798+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:03:03.797+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:03:03.837+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.156 seconds
[2025-03-10T21:03:53.885+0600] {processor.py:186} INFO - Started process (PID=81814) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:03:53.894+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:03:53.900+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:03:53.898+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:03:53.952+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:03:54.094+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:03:54.093+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:03:54.108+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:03:54.108+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:03:54.135+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.281 seconds
[2025-03-10T21:04:42.266+0600] {processor.py:186} INFO - Started process (PID=82039) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:04:42.274+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:04:42.281+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:04:42.279+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:04:42.357+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:04:42.384+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:04:42.384+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:04:42.408+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:04:42.408+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:04:42.471+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.246 seconds
[2025-03-10T21:05:32.716+0600] {processor.py:186} INFO - Started process (PID=82261) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:05:32.725+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:05:32.731+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:05:32.728+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:05:32.799+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:05:32.950+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:05:32.950+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:05:32.965+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:05:32.964+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:05:32.993+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.309 seconds
[2025-03-10T21:06:22.148+0600] {processor.py:186} INFO - Started process (PID=82489) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:06:22.149+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:06:22.152+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:06:22.151+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:06:22.185+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:06:22.205+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:06:22.204+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:06:22.222+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:06:22.222+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:06:22.260+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.136 seconds
[2025-03-10T21:07:11.911+0600] {processor.py:186} INFO - Started process (PID=82711) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:07:11.919+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:07:11.924+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:07:11.922+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:07:11.975+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:07:11.998+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:07:11.997+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:07:12.018+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:07:12.017+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:07:12.053+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.166 seconds
[2025-03-10T21:08:05.087+0600] {processor.py:186} INFO - Started process (PID=82965) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:08:05.094+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:08:05.096+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:08:05.095+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:08:05.128+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:08:05.147+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:08:05.147+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:08:05.165+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:08:05.165+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:08:05.203+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.126 seconds
[2025-03-10T21:08:56.925+0600] {processor.py:186} INFO - Started process (PID=83191) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:08:56.941+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:08:56.943+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:08:56.942+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:08:56.987+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:08:57.173+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:08:57.173+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:08:57.190+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:08:57.190+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:08:57.219+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.305 seconds
[2025-03-10T21:09:49.490+0600] {processor.py:186} INFO - Started process (PID=83421) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:09:49.497+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:09:49.499+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:09:49.498+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:09:49.532+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:09:49.555+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:09:49.555+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:09:49.582+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:09:49.582+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:09:49.624+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.151 seconds
[2025-03-10T21:10:38.745+0600] {processor.py:186} INFO - Started process (PID=83645) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:10:38.751+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:10:38.753+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:10:38.753+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:10:38.787+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:10:38.934+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:10:38.933+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:10:38.948+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:10:38.948+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:10:38.983+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.250 seconds
[2025-03-10T21:11:29.177+0600] {processor.py:186} INFO - Started process (PID=83865) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:11:29.185+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:11:29.192+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:11:29.189+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:11:29.256+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:11:29.277+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:11:29.277+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:11:29.295+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:11:29.294+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:11:29.332+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.185 seconds
[2025-03-10T21:12:18.118+0600] {processor.py:186} INFO - Started process (PID=84087) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:12:18.124+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:12:18.127+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:12:18.126+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:12:18.162+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:12:18.182+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:12:18.182+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:12:18.202+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:12:18.202+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:12:18.249+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.153 seconds
[2025-03-10T21:13:06.846+0600] {processor.py:186} INFO - Started process (PID=84343) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:13:06.853+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:13:06.856+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:13:06.855+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:13:06.905+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:13:06.930+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:13:06.929+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:13:06.949+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:13:06.949+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:13:06.975+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.150 seconds
[2025-03-10T21:13:56.516+0600] {processor.py:186} INFO - Started process (PID=84564) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:13:56.523+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:13:56.526+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:13:56.524+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:13:56.574+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:13:56.738+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:13:56.738+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:13:56.753+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:13:56.753+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:13:56.782+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.280 seconds
[2025-03-10T21:14:44.664+0600] {processor.py:186} INFO - Started process (PID=84793) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:14:44.671+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:14:44.674+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:14:44.673+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:14:44.711+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:14:44.735+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:14:44.735+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:14:44.756+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:14:44.756+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:14:44.784+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.132 seconds
[2025-03-10T21:15:33.235+0600] {processor.py:186} INFO - Started process (PID=85042) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:15:33.241+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:15:33.243+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:15:33.242+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:15:33.279+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:15:33.470+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:15:33.470+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:15:33.490+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:15:33.490+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:15:33.516+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.294 seconds
[2025-03-10T21:16:23.840+0600] {processor.py:186} INFO - Started process (PID=85276) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:16:23.844+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:16:23.845+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:16:23.845+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:16:23.883+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:16:23.905+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:16:23.905+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:16:23.927+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:16:23.927+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:16:23.954+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.126 seconds
[2025-03-10T21:17:14.576+0600] {processor.py:186} INFO - Started process (PID=85518) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:17:14.580+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:17:14.582+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:17:14.581+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:17:14.625+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:17:14.648+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:17:14.647+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:17:14.670+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:17:14.670+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:17:14.697+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.132 seconds
[2025-03-10T21:18:04.507+0600] {processor.py:186} INFO - Started process (PID=85791) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:18:04.514+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:18:04.516+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:18:04.515+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:18:04.552+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:18:04.574+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:18:04.574+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:18:04.594+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:18:04.594+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:18:04.631+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.140 seconds
[2025-03-10T21:18:54.695+0600] {processor.py:186} INFO - Started process (PID=86014) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:18:54.710+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:18:54.712+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:18:54.711+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:18:54.777+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:18:54.950+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:18:54.949+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:18:54.970+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:18:54.969+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:18:55.003+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.325 seconds
[2025-03-10T21:19:46.590+0600] {processor.py:186} INFO - Started process (PID=86260) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:19:46.606+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:19:46.608+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:19:46.607+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:19:46.644+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:19:46.671+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:19:46.671+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:19:46.693+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:19:46.692+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:19:46.721+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.145 seconds
[2025-03-10T21:20:40.506+0600] {processor.py:186} INFO - Started process (PID=86522) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:20:40.512+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:20:40.515+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:20:40.514+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:20:40.551+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:20:40.725+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:20:40.724+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:20:40.745+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:20:40.744+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:20:40.778+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.282 seconds
[2025-03-10T21:21:32.716+0600] {processor.py:186} INFO - Started process (PID=86780) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:21:32.722+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:21:32.725+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:21:32.724+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:21:32.759+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:21:32.786+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:21:32.785+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:21:32.810+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:21:32.810+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:21:32.838+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.146 seconds
[2025-03-10T21:21:53.562+0600] {processor.py:186} INFO - Started process (PID=86989) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:21:53.563+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:21:53.567+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:21:53.566+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:21:53.647+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:21:53.952+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:21:53.952+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:21:53.985+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:21:53.985+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:21:54.033+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.489 seconds
[2025-03-10T21:22:59.151+0600] {processor.py:186} INFO - Started process (PID=87152) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:22:59.157+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:22:59.160+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:22:59.159+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:22:59.195+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:22:59.219+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:22:59.219+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:22:59.242+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:22:59.241+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:22:59.266+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.126 seconds
[2025-03-10T21:23:55.793+0600] {processor.py:186} INFO - Started process (PID=87413) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:23:55.802+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:23:55.808+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:23:55.806+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:23:55.874+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:23:56.061+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:23:56.061+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:23:56.080+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:23:56.079+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:23:56.136+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.377 seconds
[2025-03-10T21:24:41.607+0600] {processor.py:186} INFO - Started process (PID=87677) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:24:41.609+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:24:41.612+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:24:41.611+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:24:41.668+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:24:41.849+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:24:41.849+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:24:41.871+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:24:41.870+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:24:41.910+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.318 seconds
[2025-03-10T21:26:28.226+0600] {processor.py:186} INFO - Started process (PID=88018) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:26:28.233+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:26:28.234+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:26:28.234+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:26:28.277+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:26:28.467+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:26:28.467+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:26:28.486+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:26:28.486+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:26:28.518+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.304 seconds
[2025-03-10T21:27:16.228+0600] {processor.py:186} INFO - Started process (PID=88265) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:27:16.235+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:27:16.237+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:27:16.236+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:27:16.282+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:27:16.325+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:27:16.324+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:27:16.356+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:27:16.356+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:27:16.394+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.187 seconds
[2025-03-10T21:28:12.564+0600] {processor.py:186} INFO - Started process (PID=88531) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:28:12.571+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:28:12.573+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:28:12.572+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:28:12.609+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:28:12.630+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:28:12.630+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:28:12.652+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:28:12.652+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:28:12.681+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.142 seconds
[2025-03-10T21:29:10.104+0600] {processor.py:186} INFO - Started process (PID=88766) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:29:10.111+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:29:10.114+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:29:10.113+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:29:10.156+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:29:10.323+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:29:10.323+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:29:10.339+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:29:10.339+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:29:10.369+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.279 seconds
[2025-03-10T21:30:00.778+0600] {processor.py:186} INFO - Started process (PID=88992) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:30:00.782+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:30:00.785+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:30:00.784+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:30:00.819+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:30:00.841+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:30:00.841+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:30:00.861+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:30:00.861+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:30:00.887+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.125 seconds
[2025-03-10T21:30:50.594+0600] {processor.py:186} INFO - Started process (PID=89216) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:30:50.596+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:30:50.599+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:30:50.598+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:30:50.639+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:30:50.820+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:30:50.819+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:30:50.840+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:30:50.840+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:30:50.877+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.294 seconds
[2025-03-10T21:31:41.416+0600] {processor.py:186} INFO - Started process (PID=89439) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:31:41.422+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:31:41.424+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:31:41.424+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:31:41.464+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:31:41.487+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:31:41.486+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:31:41.510+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:31:41.510+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:31:41.550+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.145 seconds
[2025-03-10T21:32:34.421+0600] {processor.py:186} INFO - Started process (PID=89670) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:32:34.423+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:32:34.425+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:32:34.424+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:32:34.470+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:32:34.498+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:32:34.497+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:32:34.516+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:32:34.516+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:32:34.552+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.148 seconds
[2025-03-10T21:33:29.216+0600] {processor.py:186} INFO - Started process (PID=90047) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:33:29.222+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:33:29.224+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:33:29.223+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:33:29.258+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:33:29.279+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:33:29.278+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:33:29.301+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:33:29.300+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:33:29.337+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.134 seconds
[2025-03-10T21:34:28.338+0600] {processor.py:186} INFO - Started process (PID=90770) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:34:28.344+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:34:28.346+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:34:28.345+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:34:28.382+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:34:28.590+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:34:28.589+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:34:28.616+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:34:28.616+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:34:28.677+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.351 seconds
[2025-03-10T21:35:24.388+0600] {processor.py:186} INFO - Started process (PID=91118) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:35:24.391+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:35:24.395+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:35:24.393+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:35:24.468+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:35:24.512+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:35:24.511+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:35:24.555+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:35:24.554+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:35:24.607+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.234 seconds
[2025-03-10T21:36:22.244+0600] {processor.py:186} INFO - Started process (PID=91387) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:36:22.251+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:36:22.253+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:36:22.252+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:36:22.303+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:36:22.489+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:36:22.489+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:36:22.506+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:36:22.506+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:36:22.534+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.301 seconds
[2025-03-10T21:37:55.030+0600] {processor.py:186} INFO - Started process (PID=91986) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:37:55.036+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:37:55.038+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:37:55.038+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:37:55.092+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:37:55.317+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:37:55.317+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:37:55.339+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:37:55.339+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:37:55.377+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.357 seconds
[2025-03-10T21:38:49.096+0600] {processor.py:186} INFO - Started process (PID=92238) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:38:49.103+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:38:49.105+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:38:49.104+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:38:49.154+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:38:49.354+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:38:49.354+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:38:49.379+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:38:49.378+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:38:49.421+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.339 seconds
[2025-03-10T21:39:43.629+0600] {processor.py:186} INFO - Started process (PID=92559) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:39:43.631+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:39:43.634+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:39:43.633+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:39:43.676+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:39:43.697+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:39:43.697+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:39:43.724+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:39:43.723+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:39:43.754+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.141 seconds
[2025-03-10T21:40:39.691+0600] {processor.py:186} INFO - Started process (PID=92883) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:40:39.698+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:40:39.700+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:40:39.699+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:40:39.737+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:40:39.917+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:40:39.917+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:40:39.935+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:40:39.934+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:40:39.977+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.299 seconds
[2025-03-10T21:42:01.397+0600] {processor.py:186} INFO - Started process (PID=93196) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:42:01.426+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:42:01.429+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:42:01.427+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:42:01.477+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:42:01.506+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:42:01.506+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:42:01.530+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:42:01.530+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:42:01.561+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.177 seconds
[2025-03-10T21:43:04.141+0600] {processor.py:186} INFO - Started process (PID=93498) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:43:04.147+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:43:04.159+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:43:04.155+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:43:04.216+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:43:04.243+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:43:04.242+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:43:04.265+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:43:04.265+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to None, run_after=None
[2025-03-10T21:43:04.293+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.176 seconds
[2025-03-10T21:43:42.384+0600] {processor.py:186} INFO - Started process (PID=93750) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:43:42.386+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:43:42.398+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:43:42.397+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:43:42.510+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:43:42.686+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:43:42.686+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:43:42.728+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:43:42.727+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 14:00:00+00:00, run_after=2025-03-10 14:00:00+00:00
[2025-03-10T21:43:42.762+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.429 seconds
[2025-03-10T21:44:26.410+0600] {processor.py:186} INFO - Started process (PID=93826) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:44:26.419+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:44:26.425+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:44:26.422+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:44:26.539+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:44:26.578+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:44:26.578+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:44:26.617+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:44:26.617+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-10 14:00:00+00:00, run_after=2025-03-11 14:00:00+00:00
[2025-03-10T21:44:26.647+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.269 seconds
[2025-03-10T21:44:54.689+0600] {processor.py:186} INFO - Started process (PID=94025) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:44:54.691+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:44:54.694+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:44:54.693+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:44:54.762+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:44:55.033+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:44:55.032+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:44:55.089+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:44:55.089+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:44:55.165+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.498 seconds
[2025-03-10T21:45:12.746+0600] {processor.py:186} INFO - Started process (PID=94053) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:45:12.748+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:45:12.751+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:45:12.750+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:45:12.834+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:45:12.848+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:45:12.848+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:45:12.897+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:45:12.896+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:45:12.978+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.250 seconds
[2025-03-10T21:45:49.767+0600] {processor.py:186} INFO - Started process (PID=94088) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:45:49.783+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:45:49.785+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:45:49.784+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:45:49.823+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:45:49.977+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:45:49.977+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:45:50.004+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:45:50.004+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:45:50.034+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.283 seconds
[2025-03-10T21:46:42.984+0600] {processor.py:186} INFO - Started process (PID=94338) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:46:42.999+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:46:43.003+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:46:43.001+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:46:43.058+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:46:43.271+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:46:43.271+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:46:43.323+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:46:43.323+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:46:43.373+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.413 seconds
[2025-03-10T21:47:39.883+0600] {processor.py:186} INFO - Started process (PID=94590) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:47:39.890+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:47:39.892+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:47:39.891+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:47:39.938+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:47:40.126+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:47:40.125+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:47:40.158+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:47:40.157+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:47:40.190+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.320 seconds
[2025-03-10T21:48:39.871+0600] {processor.py:186} INFO - Started process (PID=94847) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:48:39.882+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:48:39.885+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:48:39.884+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:48:39.965+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:48:40.125+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:48:40.125+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:48:40.155+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:48:40.154+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:48:40.183+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.336 seconds
[2025-03-10T21:49:34.103+0600] {processor.py:186} INFO - Started process (PID=95071) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:49:34.119+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:49:34.126+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:49:34.123+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:49:34.208+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:49:34.235+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:49:34.234+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:49:34.274+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:49:34.274+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:49:34.313+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.243 seconds
[2025-03-10T21:50:26.362+0600] {processor.py:186} INFO - Started process (PID=95309) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:50:26.367+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:50:26.369+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:50:26.369+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:50:26.414+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:50:26.587+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:50:26.587+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:50:26.623+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:50:26.623+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:50:26.664+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.316 seconds
[2025-03-10T21:51:26.044+0600] {processor.py:186} INFO - Started process (PID=95535) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:51:26.058+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:51:26.060+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:51:26.059+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:51:26.111+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:51:26.145+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:51:26.144+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:51:26.182+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:51:26.181+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:51:26.240+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.213 seconds
[2025-03-10T21:52:21.105+0600] {processor.py:186} INFO - Started process (PID=95759) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:52:21.133+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:52:21.138+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:52:21.136+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:52:21.237+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:52:21.266+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:52:21.266+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:52:21.301+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:52:21.301+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:52:21.350+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.264 seconds
[2025-03-10T21:53:15.532+0600] {processor.py:186} INFO - Started process (PID=96153) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:53:15.539+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:53:15.542+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:53:15.541+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:53:15.592+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:53:15.616+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:53:15.616+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:53:15.650+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:53:15.649+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:53:15.682+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.169 seconds
[2025-03-10T21:54:14.820+0600] {processor.py:186} INFO - Started process (PID=96609) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:54:14.824+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:54:14.828+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:54:14.826+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:54:14.942+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:54:15.211+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:54:15.211+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:54:15.252+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:54:15.251+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:54:15.298+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.500 seconds
[2025-03-10T21:55:13.265+0600] {processor.py:186} INFO - Started process (PID=96948) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:55:13.272+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:55:13.276+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:55:13.274+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:55:13.332+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:55:13.366+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:55:13.366+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:55:13.417+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:55:13.416+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:55:13.452+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.206 seconds
[2025-03-10T21:56:12.310+0600] {processor.py:186} INFO - Started process (PID=97177) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:56:12.324+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:56:12.327+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:56:12.326+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:56:12.367+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:56:12.517+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:56:12.516+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:56:12.544+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:56:12.544+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:56:12.577+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.298 seconds
[2025-03-10T21:57:04.418+0600] {processor.py:186} INFO - Started process (PID=97497) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:57:04.425+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:57:04.427+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:57:04.426+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:57:04.477+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:57:04.512+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:57:04.511+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:57:04.557+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:57:04.557+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:57:04.591+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.188 seconds
[2025-03-10T21:58:02.036+0600] {processor.py:186} INFO - Started process (PID=97759) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:58:02.041+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:58:02.043+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:58:02.042+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:58:02.086+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:58:02.110+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:58:02.110+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:58:02.143+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:58:02.142+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:58:02.169+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.148 seconds
[2025-03-10T21:58:59.335+0600] {processor.py:186} INFO - Started process (PID=98106) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:58:59.341+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:58:59.343+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:58:59.342+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:58:59.392+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:58:59.417+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:58:59.417+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:58:59.455+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:58:59.455+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:58:59.484+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.165 seconds
[2025-03-10T21:59:55.474+0600] {processor.py:186} INFO - Started process (PID=98391) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:59:55.480+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T21:59:55.482+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:59:55.482+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:59:55.524+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T21:59:55.706+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:59:55.705+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T21:59:55.736+0600] {logging_mixin.py:190} INFO - [2025-03-10T21:59:55.736+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-09 16:00:00+00:00, run_after=2025-03-10 16:00:00+00:00
[2025-03-10T21:59:55.769+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.310 seconds
[2025-03-10T22:01:21.120+0600] {processor.py:186} INFO - Started process (PID=98688) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T22:01:21.126+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T22:01:21.128+0600] {logging_mixin.py:190} INFO - [2025-03-10T22:01:21.127+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T22:01:21.173+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T22:01:21.197+0600] {logging_mixin.py:190} INFO - [2025-03-10T22:01:21.196+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T22:01:21.227+0600] {logging_mixin.py:190} INFO - [2025-03-10T22:01:21.227+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-10 16:00:00+00:00, run_after=2025-03-11 16:00:00+00:00
[2025-03-10T22:01:21.254+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.152 seconds
[2025-03-10T22:02:11.372+0600] {processor.py:186} INFO - Started process (PID=98916) to work on /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T22:02:11.378+0600] {processor.py:914} INFO - Processing file /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py for tasks to queue
[2025-03-10T22:02:11.380+0600] {logging_mixin.py:190} INFO - [2025-03-10T22:02:11.379+0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T22:02:11.426+0600] {processor.py:925} INFO - DAG(s) 'E2E_kafka_producer_data_ETL_dag' retrieved from /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py
[2025-03-10T22:02:11.583+0600] {logging_mixin.py:190} INFO - [2025-03-10T22:02:11.583+0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-10T22:02:11.616+0600] {logging_mixin.py:190} INFO - [2025-03-10T22:02:11.615+0600] {dag.py:4180} INFO - Setting next_dagrun for E2E_kafka_producer_data_ETL_dag to 2025-03-10 16:00:00+00:00, run_after=2025-03-11 16:00:00+00:00
[2025-03-10T22:02:11.653+0600] {processor.py:208} INFO - Processing /home/shamim/Real_Time_Big_Data_Airflow/dags/E2E_ETL_pipeline.py took 0.292 seconds
